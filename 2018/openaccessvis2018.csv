ReviewVenue,Publication,Title,delete,Authors,AuthorPDF,Abstract,ExplanationPage,SourceMaterials,Data,Preregistration,Video,DOI,PublicationYear,ConferenceYear,ConferenceTrack,ConferenceRoom,ConferenceDay,ConferenceSession,date,ConferenceTimeStart,ConferenceTimeEnd,
VAST,TVCG,TPFlow: Progressive Partition and Multidimensional Pattern Extraction for Large-Scale Spatio-Temporal Data Analysis ,J),"Dongyu Liu, Panpan Xu, Liu Ren",https://lliquid.github.io/homepage/files/draft_vis18_st.pdf,"Consider a multi-dimensional spatio-temporal (ST) dataset where each entry is a numerical measure defined by the corresponding temporal, spatial and other domain-specific dimensions. A typical approach to explore such data utilizes interactive visualizations with multiple coordinated views. Each view displays the aggregated measures along one or two dimensions. By brushing on the views, analysts can obtain detailed information. However, this approach often cannot provide sufficient guidance for analysts to identify patterns hidden within subsets of data. Without a priori hypotheses, analysts need to manually select and iterate through different slices to search for patterns, which can be a tedious and lengthy process. In this work, we model multidimensional ST data as tensors and propose a novel piecewise rank-one tensor decomposition algorithm which supports automatically slicing the data into homogeneous partitions and extracting the latent patterns in each partition for comparison and visual summarization. The algorithm optimizes a quantitative measure about how faithfully the extracted patterns visually represent the original data. Based on the algorithm we further propose a visual analytics framework that supports a top-down, progressive partitioning workflow for level-of-detail multidimensional ST data exploration. We demonstrate the general applicability and effectiveness of our technique on three datasets from different application domains: regional sales trend analysis, customer traffic analysis in department stores, and taxi trip analysis with origin-destination (OD) data. We further interview domain experts to verify the usability of the prototype.",,,,,video https://lliquid.github.io/homepage/files/video_vast18_tpflow_1920x1080_v7.mp4,,2018,2018,Other,"Convention Hall 1, Section C+D",Tuesday,Opening & VIS Awards & Best Papers,23-Oct,10:00 AM,10:20 AM,
InfoVis,TVCG,Formalizing Visualization Design Knowledge as Constraints: Actionable and Extensible Models in Draco ,J),"Dominik Moritz, Chenglong Wang, Greg L. Nelson, Halden Lin, Adam M. Smith, Bill Howe, Jeffrey Heer",https://www.domoritz.de/papers/2018-Draco-InfoVis.pdf,"There exists a gap between visualization design guidelines and their application in visualization tools. While empirical studies can provide design guidance, we lack a formal framework for representing design knowledge, integrating results across studies, and applying this knowledge in automated design tools that promote effective encodings and facilitate visual exploration. We propose modeling visualization design knowledge as a collection of constraints, in conjunction with a method to learn weights for soft constraints from experimental data. Using constraints, we can take theoretical design knowledge and express it in a concrete, extensible, and testable form: the resulting models can recommend visualization designs and can easily be augmented with additional constraints or updated weights. We implement our approach in Draco, a constraint-based system based on Answer Set Programming (ASP). We demonstrate how to construct increasingly sophisticated automated visualization design systems, including systems based on weights learned directly from the results of graphical perception experiments.",https://medium.com/@uwdata/draco-representing-applying-learning-visualization-design-guidelines-64ce20287e9d,https://uwdata.github.io/draco/,,,vimeo 289784521,,2018,2018,Other,"Convention Hall 1, Section C+D",Tuesday,Opening & VIS Awards & Best Papers,23-Oct,10:20 AM,10:40 AM,
SciVis,TVCG,Deadeye: A Novel Preattentive Visualization Technique Based on Dichoptic Presentation ,J),"Andrey Krekhov, Jens Krueger",,,,,,,vimeo 290325240,,2018,2018,Other,"Convention Hall 1, Section C+D",Tuesday,Opening & VIS Awards & Best Papers,23-Oct,10:40 AM,11:00 AM,
VAST,TVCG,Evaluating Multi-Dimensional Visualizations for Understanding Fuzzy Clusters ,J),"Ying Zhao, Feng Luo, Minghui Chen, Yingchao Wang, Jiazhi Xia, Fangfang Zhou, Yunhai Wang, Yi Chen, Wei Chen",,,,,,,vimeo 289787891,,2018,2018,VAST,"Convention Hall 1, Section C",Tuesday,Opening & Evaluation and Theory,23-Oct,2:20 PM,2:40 PM,
VAST,VAST,The Effect of Proximity in Social Data Charts on Perceived Unity ,C),"Marlen Promann, Sabine Brunswicker",,,,,,,vimeo 289787716,,2018,2018,VAST,"Convention Hall 1, Section C",Tuesday,Opening & Evaluation and Theory,23-Oct,2:40 PM,3:00 PM,
VAST,TVCG,Futzing and Moseying: Interviews with Professional Data Analysts on Exploration Practices ,J),"Sara Alspaugh, Nava Zokaei, Andrea Liu, Cindy Jin, Marti Hearst",,,,,,,vimeo 289787961,,2018,2018,VAST,"Convention Hall 1, Section C",Tuesday,Opening & Evaluation and Theory,23-Oct,3:00 PM,3:20 PM,
VAST,VAST,The Effect of Semantic Interaction on Foraging in Text Analysis ,C),"John Wenskovitch, Lauren Bradel, Michelle Dowling, Leanna House, Chris North",,,,,,,vimeo 289787752,,2018,2018,VAST,"Convention Hall 1, Section C",Tuesday,Opening & Evaluation and Theory,23-Oct,3:20 PM,3:40 PM,
VAST,TVCG,Cost-benefit Analysis of Visualization in Virtual Environments ,J),"Min Chen, Kelly Gaither, Nigel John, Brian McCann",,,,,,,vimeo 289787910,,2018,2018,VAST,"Convention Hall 1, Section C",Tuesday,Opening & Evaluation and Theory,23-Oct,3:40 PM,4:00 PM,
InfoVis,TVCG,Shape-preserving Star Coordinates ,J),"Vladimir Molchanov, Lars Linsen",,,,,,,vimeo 289785145,,2018,2018,InfoVis,"Convention Hall 1, Section D",Tuesday,Opening & Multiple Dimensions,23-Oct,2:20 PM,2:40 PM,
TVCG,TVCG,Using Dashboard Networks to Visualize Multiple Patient Histories: A Design Study on Post-operative Prostate Cancer ,T),"J√ºrgen Bernard, David Sessler, J√∂rn Kohlhammer, Roy A. Ruddle",http://eprints.whiterose.ac.uk/128739/1/bernard-ieee-tvcg-dashboard-networks.pdf,"In this design study, we present a visualization technique that segments patients' histories instead of treating them as raw event sequences, aggregates the segments using criteria such as the whole history or treatment combinations, and then visualizes the aggregated segments as static dashboards that are arranged in a dashboard network to show longitudinal changes. The static dashboards were developed in nine iterations, to show 15 important attributes from the patients' histories. The final design was evaluated with five non-experts, five visualization experts and four medical experts, who successfully used it to gain an overview of a 2,000 patient dataset, and to make observations about longitudinal changes and differences between two cohorts. The research represents a step-change in the detail of large-scale data that may be successfully visualized using dashboards, and provides guidance about how the approach may be generalized.",,,,,vimeo 289789053,,,2018,InfoVis,"Convention Hall 1, Section D",Tuesday,Opening & Multiple Dimensions,23-Oct,2:40 PM,3:00 PM,
InfoVis,TVCG,Towards Better Spatial Integration in Ranking Visualization ,J),"Di Weng, Ran Chen, Zikun Deng, Feiran Wu, Jingmin Chen, Yingcai Wu",http://zjuvis.org/files/srvis.pdf,"Interactive ranking techniques have substantially promoted analystsí ability in making judicious and informed decisions effectively based on multiple criteria. However, the existing techniques cannot satisfactorily support the analysis tasks involved in ranking large-scale spatial alternatives, such as selecting optimal locations for chain stores, where the complex spatial contexts involved are essential to the decision-making process. Limitations observed in the prior attempts of integrating rankings with spatial contexts motivate us to develop a context-integrated visual ranking technique. Based on a set of generic design requirements we summarized by collaborating with domain experts, we propose SRVis, a novel spatial ranking visualization technique that supports efficient spatial multi-criteria decision-making processes by addressing three major challenges in the aforementioned context integration, namely, a) the presentation of spatial rankings and contexts, b) the scalability of rankingsí visual representations, and c) the analysis of context-integrated spatial rankings. Specifically, we encode massive rankings and their cause with scalable matrix-based visualizations and stacked bar charts based on a novel two-phase optimization framework that minimizes the information loss, and the flexible spatial filtering and intuitive comparative analysis are adopted to enable the in-depth evaluation of the rankings and assist users in selecting the best spatial alternative. The effectiveness of the proposed technique has been evaluated and demonstrated with an empirical study of optimization methods, two case studies, and expert interviews.",https://srvis.zjuvis.org/,,,,vimeo 289784783,,2018,2018,InfoVis,"Convention Hall 1, Section D",Tuesday,Opening & Multiple Dimensions,23-Oct,3:00 PM,3:20 PM,
InfoVis,TVCG,A Declarative Rendering Model for Multiclass Density Maps ,J),"Jaemin Jo, Fr√©d√©ric Vernier, Pierre Dragicevic, Jean-Daniel Fekete",https://hal.inria.fr/hal-01848427/document,"Multiclass maps are scatterplots, multidimensional projections, or thematic geographic maps where data points have a categorical attribute in addition to two quantitative attributes. This categorical attribute is often rendered using shape or color, which does not scale when overplotting occurs. When the number of data points increases, multiclass maps must resort to data aggregation to remain readable. We present multiclass density maps: multiple 2D histograms computed for each of the category values. Multiclass density maps are meant as a building block to improve the expressiveness and scalability of multiclass map visualization. In this article, we first present a short survey of aggregated multiclass maps, mainly from cartography. We then introduce a declarative modelóa simple yet expressive JSON grammar associated with visual semanticsóthat specifies a wide design space of visualizations for multiclass density maps. Our declarative model is expressive and can be efficiently implemented in visualization front-ends such as modern web browsers. Furthermore, it can be reconfigured dynamically to support data exploration tasks without recomputing the raw data. Finally, we demonstrate how our model can be used to reproduce examples from the past and support exploring data at scale.",https://jaeminjo.github.io/Multiclass-Density-Maps/,https://github.com/e-/Multiclass-Density-Maps,,,vimeo 289785026,,2018,2018,InfoVis,"Convention Hall 1, Section D",Tuesday,Opening & Multiple Dimensions,23-Oct,3:20 PM,3:40 PM,
InfoVis,TVCG,DimReader: Axis lines that explain non-linear projections ,J),"Rebecca Faust, David Glickenstein, Carlos Scheidegger",https://arxiv.org/pdf/1710.00992.pdf,"Non-linear dimensionality reduction (NDR) methods such as LLE and t-SNE are popular with visualization researchers and experienced data analysts, but present serious problems of interpretation. In this paper, we present DimReader, a technique that recovers readable axes from such techniques. DimReader is based on analyzing infinitesimal perturbations of the dataset with respect to variables of interest. The perturbations define exactly how we want to change each point in the original dataset and we measure the effect that these changes have on the projection. The recovered axes are in direct analogy with the axis lines (grid lines) of traditional scatterplots. We also present methods for discovering perturbations on the input data that change the projection the most. The calculation of the perturbations is efficient and easily integrated into programs written in modern programming languages. We present results of DimReader on a variety of NDR methods and datasets both synthetic and real-life, and show how it can be used to compare different NDR methods. Finally, we discuss limitations of our proposal and situations where further research is needed.",,,,,vimeo 289784574,,2018,2018,InfoVis,"Convention Hall 1, Section D",Tuesday,Opening & Multiple Dimensions,23-Oct,3:40 PM,4:00 PM,
SciVis,TVCG,Recirculation Surfaces for Flow Visualization ,J),"Thomas Wilde, Christian R√∂ssl, Holger Theisel",,,,,,,vimeo 290325803,,2018,2018,SciVis,Estrel Hall A+B,Tuesday,Opening & Flow Features,23-Oct,2:20 PM,2:40 PM,
SciVis,TVCG,Objective Vortex Corelines of Finite-sized Objects in Fluid Flows ,J),"Tobias G√ºnther, Holger Theisel",,,,,,,vimeo 290327685,,2018,2018,SciVis,Estrel Hall A+B,Tuesday,Opening & Flow Features,23-Oct,2:40 PM,3:00 PM,
TVCG,TVCG,Towards High-quality Visualization of Superfluid Vortices ,T),"Yulong Guo, Xiaopei Liu, Chi Xiong, Xuemiao Xu, Chi-Wing Fu",,,,,,,vimeo 289788863,,,2018,SciVis,Estrel Hall A+B,Tuesday,Opening & Flow Features,23-Oct,3:00 PM,3:20 PM,
TVCG,TVCG,Semantic Flow Graph: A Framework for Discovering Object Relationships in Flow Fields ,T),"Jun Tao, Chaoli Wang, Nitesh Chawla, Lei Shi, Seung Hyun Kim",,,,,,,vimeo 289789101,,,2018,SciVis,Estrel Hall A+B,Tuesday,Opening & Flow Features,23-Oct,3:20 PM,3:40 PM,
VAST,TVCG,Visual Abstraction of the Large Scale Geospatial Origin-Destination Movement Data ,J),"Zhiguang Zhou, Linhao Meng, Cheng Tang, Ying Zhao, Zhiyong Guo, Miaoxin Hu, Wei Chen",,,,,,,vimeo 289787224,,2018,2018,VAST,"Convention Hall 1, Section C",Tuesday,Spatio-Temporal Data,23-Oct,4:20 PM,4:40 PM,
VAST,TVCG,Analysis of Flight Variability: a Systematic Approach ,J),"Natalia Andrienko, Gennady Andrienko, Jose Manuel Cordero Garcia, David Scarlatti",,,,,,,vimeo 289787283,,2018,2018,VAST,"Convention Hall 1, Section C",Tuesday,Spatio-Temporal Data,23-Oct,4:40 PM,5:00 PM,
VAST,TVCG,ForVizor: Visualizing Spatio-Temporal Team Formations in Soccer ,J),"Yingcai Wu, Xiao Xie, Jiachen Wang, Dazhen Deng, Hongye Liang, Hui Zhang, Shoubin Cheng, Wei Chen",,,,,,,vimeo 289787566,,2018,2018,VAST,"Convention Hall 1, Section C",Tuesday,Spatio-Temporal Data,23-Oct,5:00 PM,5:20 PM,
VAST,TVCG,MotionRugs: Visualizing Collective Trends in Space and Time ,J),"Juri Buchmuller, Dominik Jackle, Eren Cakmak, Ulrik Brandes, Daniel Keim",,,,,,,vimeo 289787684,,2018,2018,VAST,"Convention Hall 1, Section C",Tuesday,Spatio-Temporal Data,23-Oct,5:20 PM,5:40 PM,
VAST,TVCG,Identification of Temporally Varying Areas of Interest in Long Duration Eye Tracking Data Sets ,J),"Prithiviraj Kaliappa Gounder Muthumanickam, Katerina Vrotsou, Aida Nordman, Jimmy Johansson, Matthew Cooper",,,,,,,vimeo 289787582,,2018,2018,VAST,"Convention Hall 1, Section C",Tuesday,Spatio-Temporal Data,23-Oct,5:40 PM,6:00 PM,
InfoVis,TVCG,A Heuristic Approach to Value-Driven Evaluation of Visualizations ,J),"Emily Wall, Meeshu Agnihotri, Laura Matzen, Kristin Divis, Michael Haass, Alex Endert, John Stasko",https://www.cc.gatech.edu/~ewall9/media/papers/ValueVIS2018.pdf,"Recently, an approach for determining the value of a visualization was proposed, one moving beyond simple measurements of task accuracy and speed. The value equation contains components for the time savings a visualization provides, the insights and insightful questions it spurs, the overall essence of the data it conveys, and the confidence about the data and its domain it inspires. This articulation of value is purely descriptive, however, providing no actionable method of assessing a visualizationís value. In this work, we create a heuristic-based evaluation methodology to accompany the value equation for assessing interactive visualizations. We refer to the methodology colloquially as ICE-T, based on an anagram of the four value components. Our approach breaks the four components down into guidelines, each of which is made up of a small set of low-level heuristics. Evaluators who have knowledge of visualization design principles then assess the visualization with respect to the heuristics. We conducted an initial trial of the methodology on three interactive visualizations of the same data set, each evaluated by 15 visualization experts. We found that the methodology showed promise, obtaining consistent ratings across the three visualizations and mirroring judgments of the utility of the visualizations by instructors of the course in which they were developed.",,,,,vimeo 289784928,,2018,2018,InfoVis,"Convention Hall 1, Section D",Tuesday,Evaluation & Applications,23-Oct,4:20 PM,4:40 PM,
InfoVis,TVCG,Patterns and Pace: Quantifying Diverse Exploration Behavior with Visualizations on the Web ,J),"Mi Feng, Evan Peck, Lane Harrison",https://osf.io/9wqgk/,"The diverse and vibrant ecosystem of interactive visualizations on the web presents an opportunity for researchers and practitioners to observe and analyze how everyday people interact with data visualizations. However, existing metrics of visualization interaction behavior used in research do not fully reveal the breadth of peoplesí open-ended explorations with visualizations. One possible way to address this challenge is to determine high-level goals for visualization interaction metrics, and infer corresponding features from user interaction data that characterize different aspects of peoplesí explorations of visualizations. In this paper, we address this challenge by identifying needs for visualization behavior analysis, and by developing corresponding candidate features that can be inferred from usersí interaction data with visualization. We then propose metrics that capture novel aspects of peoplesí open-ended explorations, including exploration uniqueness and exploration pacing. We evaluate these metrics along with four other metrics recently proposed in visualization literature by applying them to interaction data from prior visualization studies. The results of these evaluations suggest that these new metrics 1) reveal new characteristics of peoplesí use of visualizations, 2) can be used to evaluate statistical differences between visualization designs, and 3) are statistically independent of prior metrics used in visualization research. We discuss implications of these results for future studies, including the potential for applying these metrics in visualization interaction analysis, as well as emerging challenges in developing a design space of metrics for visualization engagement.",,,https://osf.io/dx43q/wiki/home/,,vimeo 289785167,,2018,2018,InfoVis,"Convention Hall 1, Section D",Tuesday,Evaluation & Applications,23-Oct,4:40 PM,5:00 PM,
TVCG,TVCG,Lineage: Visualizing Multivariate Clinical Data in Genealogy Graphs ,T),"Carolina Nobre, Nils Gehlenborg, Hilary Coon, Alexander Lex",http://sci.utah.edu/~vdl/papers/2018_tvcg_lineage.pdf,"The majority of diseases that are a significant challenge for public and individual heath are caused by a combination of hereditary and environmental factors. In this paper we introduce Lineage, a novel visual analysis tool designed to support domain experts who study such multifactorial diseases in the context of genealogies. Incorporating familial relationships between cases with other data can provide insights into shared genomic variants and shared environmental exposures that may be implicated in such diseases. We introduce a data and task abstraction, and argue that the problem of analyzing such diseases based on genealogical, clinical, and genetic data can be mapped to a multivariate graph visualization problem. The main contribution of our design study is a novel visual representation for tree-like, multivariate graphs, which we apply to genealogies and clinical data about the individuals in these families. We introduce data-driven aggregation methods to scale to multiple families. By designing the genealogy graph layout to align with a tabular view, we are able to incorporate extensive, multivariate attributes in the analysis of the genealogy without cluttering the graph. We validate our designs by conducting case studies with our domain collaborators.",,https://github.com/caleydo/lineage,,,vimeo 289789223,,,2018,InfoVis,"Convention Hall 1, Section D",Tuesday,Evaluation & Applications,23-Oct,5:00 PM,5:20 PM,
InfoVis,TVCG,IDMVis: Temporal Event Sequence Visualization for Type 1 Diabetes Treatment Decision Support ,J),"Yixuan Zhang, Kartik Chanana, Cody Dunne",https://github.com/zjanice/PHI/blob/master/IDMVis_IEEEVIS18_preprint.pdf,"Type 1 diabetes is a chronic, incurable autoimmune disease affecting millions of Americans in which the body stops producing insulin and blood glucose levels rise. The goal of intensive diabetes management is to lower average blood glucose through frequent adjustments to insulin protocol, diet, and behavior. Manual logs and medical device data are collected by patients, but these multiple sources are presented in disparate visualization designs to the clinicianómaking temporal inference difficult. We conducted a design study over 18 months with clinicians performing intensive diabetes management. We present a data abstraction and novel hierarchical task abstraction for this domain. We also contribute IDMVis: a visualization tool for temporal event sequences with multidimensional, interrelated data. IDMVis includes a novel technique for folding and aligning records by dual sentinel events and scaling the intermediate timeline. We validate our design decisions based on our domain abstractions, best practices, and through a qualitative evaluation with six clinicians. The results of this study indicate that IDMVis accurately reflects the workflow of clinicians. Using IDMVis, clinicians are able to identify issues of data quality such as missing or conflicting data, reconstruct patient records when data is missing, differentiate between days with different patterns, and promote educational interventions after identifying discrepancies.",,https://github.com/VisDunneRight/IDMVis,,,vimeo 289785100,,2018,2018,InfoVis,"Convention Hall 1, Section D",Tuesday,Evaluation & Applications,23-Oct,5:20 PM,5:40 PM,
TVCG,TVCG,Visualization of Cultural Heritage Collection Data: State of the Art and Future Challenges ,T),"Florian Windhager, Paolo Federico, G√ºnther Schreder, Katrin Glinka, Marian D√∂rk, Silvia Miksch, Eva Mayr",,,,,,,vimeo 289789286,,,2018,InfoVis,"Convention Hall 1, Section D",Tuesday,Evaluation & Applications,23-Oct,5:40 PM,6:00 PM,
SciVis,TVCG,Interactive Visualization of RNA and DNA Structures ,J),"Norbert Lindow, Daniel Baum, Morgan Leborgne, Hans-Christian Hege",,,,,,,vimeo 290325417,,2018,2018,SciVis,Estrel Hall A+B,Tuesday,Biological Applications,23-Oct,4:20 PM,4:40 PM,
SciVis,TVCG,Labels on Levels: Labeling of Multi-Scale Multi-Instance and Crowded 3D Biological Environments ,J),"David Kou≈ôil, Ladislav ƒåmol√≠k, Barbora Kozl√≠kov√°, Hsiang-Yun Wu, Graham Johnson, David S. Goodsell, Arthur Olson, Eduard Gr√∂ller, Ivan Viola",,,,,,,vimeo 290325281,,2018,2018,SciVis,Estrel Hall A+B,Tuesday,Biological Applications,23-Oct,4:40 PM,5:00 PM,
SciVis,TVCG,Visualization of Large Molecular Trajectories ,J),"David Duran Rosich, Pedro Hermosilla Casajus, Timo Ropinski, Barbora Kozl√≠kov√°, √Älvar Vinacua, Pere-Pau V√°zquez",,,,,,,vimeo 290328133,,2018,2018,SciVis,Estrel Hall A+B,Tuesday,Biological Applications,23-Oct,5:00 PM,5:20 PM,
TVCG,TVCG,Robust Tracing and Visualization of Heterogeneous Microvascular Networks ,T),"Pavel Govyadinov, Tasha Womack, Jason L. Eriksen, Guoning Chen, David Mayerich",,,,,,,vimeo 289789196,,,2018,SciVis,Estrel Hall A+B,Tuesday,Biological Applications,23-Oct,5:20 PM,5:40 PM,
VAST,TVCG,Visual Analysis of the Temporal Evolution of Ensemble Forecast Sensitivities ,J),"Alexander Kumpf, Marc Rautenhaus, Michael Riemer, R√ºdiger Westermann",,,,,,,vimeo 289787833,,2018,2018,VAST,"Convention Hall 1, Section C",Wednesday,Ensemble and Provenance,24-Oct,9:00 AM,9:20 AM,
VAST,TVCG,EnsembleLens: Ensemble-based Visual Exploration of Anomaly Detection Algorithms with Multidimensional Data ,J),"Ke Xu, Meng Xia, Xing Mu, Yun Wang, Nan Cao",,,,,,,vimeo 289787339,,2018,2018,VAST,"Convention Hall 1, Section C",Wednesday,Ensemble and Provenance,24-Oct,9:20 AM,9:40 AM,
TVCG,TVCG,Exploring Variability within Ensembles of Decadal Climate Predictions ,T),"Christopher P. Kappe, Michael B√∂ttinger, Heike Leitte",,,,,,,vimeo 289789327,,,2018,VAST,"Convention Hall 1, Section C",Wednesday,Ensemble and Provenance,24-Oct,9:40 AM,10:00 AM,
VAST,TVCG,KnowledgePearls: Provenance-Based Visualization Retrieval ,J),"Holger Stitz, Samuel Gratzl, Harald Piringer, Thomas Zichner, Marc Streit",,,,,,,vimeo 289787528,,2018,2018,VAST,"Convention Hall 1, Section C",Wednesday,Ensemble and Provenance,24-Oct,10:00 AM,10:20 AM,
VAST,TVCG,Enhancing Web-based Analytics Applications through Provenance ,J),"Akhilesh Camisetty, Chaitanya Chandurkar, Maoyuan Sun, David Koop",,,,,,,vimeo 289787554,,2018,2018,VAST,"Convention Hall 1, Section C",Wednesday,Ensemble and Provenance,24-Oct,10:20 AM,10:40 AM,
InfoVis,TVCG,Comparing Similarity Perception in Time Series Visualizations ,J),"Anna Gogolou, Theophanis Tsandilas, Themis Palpanas, Anastasia Bezerianos",https://hal.inria.fr/hal-01845008/document,"A common challenge faced by many domain experts working with time series data is how to identify and compare similar patterns. This operation is fundamental in high-level tasks, such as detecting recurring phenomena or creating clusters of similar temporal sequences. While automatic measures exist to compute time series similarity, human intervention is often required to visually inspect these automatically generated results. The visualization literature has examined similarity perception and its relation to automatic similarity measures for line charts, but has not yet considered if alternative visual representations, such as horizon graphs and colorfields, alter this perception. Motivated by how neuroscientists evaluate epileptiform patterns, we conducted two experiments that study how these three visualization techniques affect similarity perception in EEG signals. We seek to understand if the time series results returned from automatic similarity measures are perceived in a similar manner, irrespective of the visualization technique; and if what people perceive as similar with each visualization aligns with different automatic measures and their similarity constraints. Our findings indicate that horizon graphs align with similarity measures that allow local variations in temporal position or speed (i.e., dynamic time warping) more than the two other techniques. On the other hand, horizon graphs do not align with measures that are insensitive to amplitude and y-offset scaling (i.e., measures based on z-normalization), but the inverse seems to be the case for line charts and colorfields. Overall, our work indicates that the choice of visualization affects what temporal patterns we consider as similar, i.e., the notion of similarity in time series is not visualization independent.",,,,,vimeo 289785077,,2018,2018,InfoVis,"Convention Hall 1, Section D",Wednesday,Time,24-Oct,9:00 AM,9:20 AM,
TVCG,TVCG,A Multiresolution Streamgraph Approach to Explore Hierarchical Time Series ,T),"Erick Cuenca, Arnaud Sallaberry, Florence Ying Wang, Pascal Poncelet",http://www.lirmm.fr/~poncelet/publications/papers/Multistream2018.pdf,"Multiple time series are a set of multiple quantitative variables occurring at the same interval. They are present in many domains such as medicine, finance, and manufacturing for analytical purposes. In recent years, streamgraph visualization (evolved from ThemeRiver) has been widely used for representing temporal evolution patterns in multiple time series. However, streamgraph as well as ThemeRiver suffer from scalability problems when dealing with several time series. To solve this problem, multiple time series can be organized into a hierarchical structure where individual time series are grouped hierarchically according to their proximity. In this paper, we present a new streamgraph-based approach to convey the hierarchical structure of multiple time series to facilitate the exploration and comparisons of temporal evolution. Based on a focus+context technique, our method allows time series exploration at different granularities (e. g., from overview to details). To illustrate our approach, two usage examples are presented.",http://advanse.lirmm.fr/multistream/,https://github.com/erickedu85/multistream,,,vimeo 289789365,,,2018,InfoVis,"Convention Hall 1, Section D",Wednesday,Time,24-Oct,9:20 AM,9:40 AM,
TVCG,TVCG,Line Graph or Scatter Plot? Automatic Selection of Methods for Visualizing Trends in Time Series ,T),"Yunhai Wang, Fubo Han, Lifeng Zhu, Oliver Deussen, Baoquan Chen",http://www.yunhaiwang.org/vis-selection/timeseries.pdf,"Line graphs are usually considered to be the best choice for visualizing time series data, whereas sometimes also scatter plots are used for showing main trends. So far there are no guidelines that indicate which of these visualization methods better display trends in time series for a given canvas. Assuming that the main information in a time series is its overall trend, we propose an algorithm that automatically picks the visualization method that reveals this trend best. This is achieved by measuring the visual consistency between the trend curve represented by a LOESS fit and the trend described by a scatter plot or a line graph. To measure the consistency between our algorithm and user choices, we performed an empirical study with a series of controlled experiments that show a large correspondence. In a factor analysis we furthermore demonstrate that various visual and data factors have effects on the preference for a certain type of visualization.",,,,,vimeo 289788836,,,2018,InfoVis,"Convention Hall 1, Section D",Wednesday,Time,24-Oct,9:40 AM,10:00 AM,
TVCG,TVCG,A Vector Field Design Approach to Animated Transitions ,T),"Yong Wang, Daniel Archambault, Carlos E. Scheidegger, Huamin Qu",http://www.cs.swansea.ac.uk/~csdarchambault/publications/animatedTransitionFinalSubVersion.pdf,"Animated transitions can be effective in explaining and exploring a small number of visualizations where there are drastic changes in the scene over a short interval of time. This is especially true if data elements cannot be visually distinguished by other means. Current research in animated transitions has mainly focused on linear transitions (all elements follow straight line paths) or enhancing coordinated motion through bundling of linear trajectories. In this paper, we introduce animated transition design, a technique to build smooth, non-linear transitions for clustered data with either minimal or no user involvement. The technique is flexible and simple to implement, and has the additional advantage that it explicitly enhances coordinated motion and can avoid crowding, which are both important factors to support object tracking in a scene. We investigate its usability, provide preliminary evidence for the effectiveness of this technique through metric evaluations and user study and discuss limitations and future directions.",,,,,vimeo 289789555,,,2018,InfoVis,"Convention Hall 1, Section D",Wednesday,Time,24-Oct,10:00 AM,10:20 AM,
InfoVis,TVCG,Temporal Treemaps: Static Visualization of Evolving Trees ,J),"Wiebke K√∂pp, Tino Weinkauf",http://www.csc.kth.se/~weinkauf/publications/documents/koepp19a.pdf,"We consider temporally evolving trees with changing topology and data: tree nodes may persist for a time range, merge or split, and the associated data may change. Essentially, one can think of this as a time series of trees with a node correspondence per hierarchy level between consecutive time steps. Existing visualization approaches for such data include animated 2D treemaps, where the dynamically changing layout makes it difficult to observe the data in its entirety. We present a method to visualize this dynamic data in a static, nested, and space-filling visualization. This is based on two major contributions: First, the layout constitutes a graph drawing problem. We approach it for the entire time span at once using a combination of a heuristic and simulated annealing. Second, we propose a rendering that emphasizes the hierarchy through an adaption of the classic cushion treemaps. We showcase the wide range of applicability using data from feature tracking in time-dependent scalar fields, evolution of file system hierarchies, and world population.",http://www.csc.kth.se/~weinkauf/publications/documents/koepp19a_algorithm.mp4,,,,vimeo 289784452,,2018,2018,InfoVis,"Convention Hall 1, Section D",Wednesday,Time,24-Oct,10:20 AM,10:40 AM,
SciVis,TVCG,Visual Analysis of Aneurysm Data using Statistical Graphics ,J),"Monique Meuschke, Tobias G√ºnther, Philipp Berg, Ralph Wickenhoefer, Markus Gross, Bernhard Preim, Kai Lawonn",,,,,,,vimeo 290325604,,2018,2018,SciVis,Estrel Hall A+B,Wednesday,Biomedical Visualization,24-Oct,9:00 AM,9:20 AM,
SciVis,TVCG,Interactive Visualization of 3D Histopathology in Native Resolution ,J),"Martin Falk, Anders Ynnerman, Darren Treanor, Claes Lundstr√∂m",,,,,,,vimeo 290325921,,2018,2018,SciVis,Estrel Hall A+B,Wednesday,Biomedical Visualization,24-Oct,9:20 AM,9:40 AM,
SciVis,TVCG,Visualization of Neuronal Structures in Wide-field Microscopy Brain Images ,J),"Saeed Boorboor, Shreeraj Jadhav, Mala Ananth, David Talmage, Lorna W Role, Arie Kaufman",,,,,,,vimeo 290328215,,2018,2018,SciVis,Estrel Hall A+B,Wednesday,Biomedical Visualization,24-Oct,9:40 AM,10:00 AM,
TVCG,TVCG,Classification of Blood Flow Patterns in Cerebral Aneurysms ,T),"Monique Meuschke, Steffen Oeltze-Jafra, Oliver Beuing, Bernhard Preim, Kai Lawonn",,,,,,,vimeo 289789890,,,2018,SciVis,Estrel Hall A+B,Wednesday,Biomedical Visualization,24-Oct,10:00 AM,10:20 AM,
TVCG,TVCG,Bridging Text Visualization and Mining: A Task-Driven Survey ,T),"Shixia Liu, Xiting Wang, Christopher Collins, Wenwen Dou, Fangxin Ouyang, Mennatallah El-Assady, Liu Jiang, Daniel Keim",,,,,,,vimeo 289789579,,,2018,VAST,Estrel Hall C,Wednesday,Text,24-Oct,9:00 AM,9:20 AM,
VAST,TVCG,Doccurate: A Curation-Based Approach for Clinical Text Visualization ,J),Nicole Sultanum,,,,,,,vimeo 289787431,,2018,2018,VAST,Estrel Hall C,Wednesday,Text,24-Oct,9:20 AM,9:40 AM,
VAST,TVCG,VIS Author Profiles: Interactive Descriptions of Publication Records Combining Text and Visualization ,J),"Shahid Latif, Fabian Beck, Devin Singh, Michael Brudno, Fanny Chevalier",,,,,,,vimeo 289787504,,2018,2018,VAST,Estrel Hall C,Wednesday,Text,24-Oct,9:40 AM,10:00 AM,
TVCG,TVCG,A Visual Analytics Framework for Identifying Topic Drivers in Media ,T),"Yafeng Lu, Hong Wang, Steven Landis, Ross Maciejewski",,,,,,,vimeo 289788885,,,2018,VAST,Estrel Hall C,Wednesday,Text,24-Oct,10:00 AM,10:20 AM,
TVCG,TVCG,Visualizing a Thinker‚Äôs Life ,T),"Patrick Riehmann, Dora Kiesel, Martin Kohlhaas, Bernd Fr√∂hlich",,,,,,,vimeo 289789544,,,2018,VAST,Estrel Hall C,Wednesday,Text,24-Oct,10:20 AM,10:40 AM,
TVCG,TVCG,Commercial Visual Analytics Systems ‚Äì Advances in the Big Data Analytics Field ,T),"Michael Behrisch, Dirk Streeb, Florian Stoffel, Daniel Seebacher, Stefan Hagen Weber, Sebastian Mittelstaedt, Hanspeter Pfister, Daniel Keim",,,,,,,vimeo 289789498,,,2018,VAST,"Convention Hall 1, Section C",Wednesday,Applications,24-Oct,11:00 AM,11:20 AM,
VAST,TVCG,BitExTract: Interactive Visualization for Extracting Bitcoin Exchange Intelligence ,J),"Xuanwu Yue, Xinhuan Shu, Xinyu ZHU, Xinnan Du, Zheqing Yu, Dimitrios Papadopoulos, Siyuan Liu",,,,,,,vimeo 289787312,,2018,2018,VAST,"Convention Hall 1, Section C",Wednesday,Applications,24-Oct,11:20 AM,11:40 AM,
TVCG,TVCG,KAVAGait: Knowledge-Assisted Visual Analytics for Clinical Gait Analysis ,T),"Markus Wagner, Djordje Slijepcevic, Brian Horsak, Alexander Rind, Matthias Zeppelzauer, Wolfgang Aigner",,,,,,,vimeo 289788975,,,2018,VAST,"Convention Hall 1, Section C",Wednesday,Applications,24-Oct,11:40 AM,12:00 PM,
TVCG,TVCG,Precision Risk Analysis of Cancer Therapy with Interactive Nomograms and Survival Plots ,T),"G.Elisabeta Marai, Chihua Ma, Andrew T. Burks, Filippo Pellolio, Guadalupe Canahuate, David M. Vock, Abdallah S.R. Mohamed, C. David Fuller",,,,,,,vimeo 289789079,,,2018,VAST,"Convention Hall 1, Section C",Wednesday,Applications,24-Oct,12:00 PM,12:20 PM,
VAST,VAST,VUSphere: Visual Analysis of Video Utilization in Online Distance Education ,C),"Huan He, Qinghua Zheng, Bo Dong",,,,,,,vimeo 289788052,,2018,2018,VAST,"Convention Hall 1, Section C",Wednesday,Applications,24-Oct,12:20 PM,12:40 PM,
InfoVis,TVCG,Juniper: A Tree+Table Approach to Multivariate Graph Visualization ,J),"Carolina Nobre, Marc Streit, Alexander Lex",http://sci.utah.edu/~vdl/papers/2018_infovis_juniper.pdf,"Analyzing large, multivariate graphs is an important problem in many domains, yet such graphs are challenging to visualize. In this paper, we introduce a novel, scalable, tree+table multivariate graph visualization technique, which makes many tasks related to multivariate graph analysis easier to achieve. The core principle we follow is to selectively query for nodes or subgraphs of interest and visualize these subgraphs as a spanning tree of the graph. The tree is laid out linearly, which enables us to juxtapose the nodes with a table visualization where diverse attributes can be shown. We also use this table as an adjacency matrix, so that the resulting technique is a hybrid node-link/adjacency matrix technique. We implement this concept in Juniper and complement it with a set of interaction techniques that enable analysts to dynamically grow, restructure, and aggregate the tree, as well as change the layout or show paths between nodes. We demonstrate the utility of our tool in usage scenarios for different multivariate networks: a bipartite network of scholars, papers, and citation metrics and a multitype network of story characters, places, books, etc.",,https://github.com/caleydo/lineage/tree/juniper,,,vimeo 289784894,,2018,2018,InfoVis,"Convention Hall 1, Section D",Wednesday,Graphs & Trees,24-Oct,11:00 AM,11:20 AM,
TVCG,TVCG,Graph Thumbnails: Identifying and Comparing Multiple Graphs at a Glance ,T),"Vahan Yoghourdjian, Tim Dwyer, Karsten Klein, Kim Marriott, Michael Wybrow",http://vahany.com/docs/Graph_Thumbnails_preprint.pdf,"We propose <i>Graph Thumbnails</i>, small icon-like visualisations of the high-level structure of network data. Graph Thumbnails are designed to be legible in small multiples to support rapid browsing within large graph corpora. Compared to existing graph-visualisation techniques our representation has several advantages: (1) the visualisation can be computed in linear time; (2) it is canonical in the sense that isomorphic graphs will always have identical thumbnails; and (3) it provides precise information about the graph structure. We report the results of two user studies. The first study compares Graph Thumbnails to node-link and matrix views for identifying similar graphs. The second study investigates the comprehensibility of the different representations. We demonstrate the usefulness of this representation for summarising the evolution of protein-protein interaction networks across a range of species.",,,,,vimeo 289789353,,,2018,InfoVis,"Convention Hall 1, Section D",Wednesday,Graphs & Trees,24-Oct,11:20 AM,11:40 AM,
InfoVis,TVCG,Structure-Based Suggestive Exploration: A New Approach for Effective Exploration of Large Networks ,J),"Fangzhou Guo, Wei Chen, Dongming Han, Jiacheng Pan, Xiaotao Nie, Jiazhi Xia, Xiaolong (Luke) Zhang",http://www.cad.zju.edu.cn/home/vagblog/VAG_Work/Structure-Based%20Suggestive%20Exploration.pdf,"When analyzing a visualized network, users need to explore different sections of the network to gain insight. However, effective exploration of large networks is often a challenge. While various tools are available for users to explore the global and local features of a network, these tools usually require significant interaction activities, such as repetitive navigation actions to follow network nodes and edges. In this paper, we propose a structure-based suggestive exploration approach to support effective exploration of large networks by suggesting appropriate structures upon user request. Encoding nodes with vectorized representations by transforming information of surrounding structures of nodes into a high dimensional space, our approach can identify similar structures within a large network, enable user interaction with multiple similar structures simultaneously, and guide the exploration of unexplored structures. We develop a web-based visual exploration system to incorporate this suggestive exploration approach and compare performances of our approach under different vectorizing methods and networks. We also present the usability and effectiveness of our approach through a controlled user study with two datasets.",,,,,vimeo 289785045,,2018,2018,InfoVis,"Convention Hall 1, Section D",Wednesday,Graphs & Trees,24-Oct,11:40 AM,12:00 PM,
InfoVis,TVCG,Structure-aware Fisheye Views for Efficient Large Graph Exploration ,J),"Yunhai Wang, Yanyan Wang, Yinqi Sun, Haifeng Zhang, Chi-Wing Fu, Michael Sedlmair, Baoquan Chen, Oliver Deussen",http://www.yunhaiwang.org/infovis18/fisheye/vis18b-sub1214-cam-i7.pdf,"Traditional fisheye views for exploring large graphs introduce substantial distortions that often lead to a decreased readability of paths and other interesting structures. To overcome these problems, we propose a framework for <i>structure-aware</i> fisheye views. Using edge orientations as constraints for graph layout optimization allows us not only to reduce spatial and temporal distortions during fisheye zooms, but also to improve the readability of the graph structure. Furthermore, the framework enables us to optimize fisheye lenses towards specific tasks and design a family of new lenses: polyfocal, cluster, and path lenses. A GPU implementation lets us process large graphs with up to 15,000 nodes at interactive rates. A comprehensive evaluation, a user study, and two case studies demonstrate that our structure-aware fisheye views improve layout readability and user performance.",,,,,vimeo 289785238,,2018,2018,InfoVis,"Convention Hall 1, Section D",Wednesday,Graphs & Trees,24-Oct,12:00 PM,12:20 PM,
InfoVis,TVCG,"Graphicle: Exploring Units, Networks, and Context in a Blended Visualization Approach ",J),"Timothy Major, Rahul C. Basole",http://entsci.gatech.edu/resources/basole-2019-tvcg-graphicle.pdf,"Many real-world datasets are large, multivariate, and relational in nature and relevant associated decisions frequently require a simultaneous consideration of both attributes and connections. Existing visualization systems and approaches, however, often make an explicit trade-off between either affording rich exploration of individual data units and their attributes or exploration of the underlying network structure. In doing so, important analysis opportunities and insights are potentially missed. In this study, we aim to address this gap by (1) considering visualizations and interaction techniques that blend the spectrum between unit and network visualizations, (2) discussing the nature of different forms of contexts and the challenges in implementing them, and (3) demonstrating the value of our approach for visual exploration of multivariate, relational data for a real-world use case. Specifically, we demonstrate through a system called Graphicle how network structure can be layered on top of unit visualization techniques to create new opportunities for visual exploration of physician characteristics and referral data. We report on the design, implementation, and evaluation of the system and effectiveness of our blended approach.",,,,,vimeo 262664447,,2018,2018,InfoVis,"Convention Hall 1, Section D",Wednesday,Graphs & Trees,24-Oct,12:20 PM,12:40 PM,
SciVis,TVCG,Interactive Obstruction-free Lensing for Volumetric Data Visualization ,J),"Michael Traor√©, Christophe Hurter, Alexandru Telea",,,,,,,vimeo 290325542,,2018,2018,SciVis,Estrel Hall A+B,Wednesday,Volume Visualization,24-Oct,11:00 AM,11:20 AM,
SciVis,TVCG,Dynamic Volume Lines: Visual Comparison of 3D Volumes through Space-filling Curves ,J),"Johannes Weissenb√∂ck, Bernhard Fr√∂hler, Eduard Gr√∂ller, Johann Kastner, Christoph Heinzl",,,,,,,vimeo 290325634,,2018,2018,SciVis,Estrel Hall A+B,Wednesday,Volume Visualization,24-Oct,11:20 AM,11:40 AM,
SciVis,TVCG,A Declarative Grammar of Flexible Volume Visualization Pipelines ,J),"Min Shih, Charles Rozhon, Kwan-Liu Ma",,,,,,,vimeo 290327611,,2018,2018,SciVis,Estrel Hall A+B,Wednesday,Volume Visualization,24-Oct,11:40 AM,12:00 PM,
TVCG,TVCG,Multi-Material Volume Rendering with a Physically-Based Surface Reflection Model ,T),"Oleg Igouchkine, Yubo Zhang, Kwan-Liu Ma",,,,,,,vimeo 289789120,,,2018,SciVis,Estrel Hall A+B,Wednesday,Volume Visualization,24-Oct,12:00 PM,12:20 PM,
TVCG,TVCG,A Generative Model for Volume Rendering ,T),"Matthew Berger, Jixian Li, Joshua A. Levine",,,,,,,vimeo 289789468,,,2018,SciVis,Estrel Hall A+B,Wednesday,Volume Visualization,24-Oct,12:20 PM,12:40 PM,
InfoVis,TVCG,Vistrates: A Component Model for Ubiquitous Analytics ,J),"Sriram Karthik Badam, Andreas Mathisen, Roman R√§dle, Clemens Nylandsted Klokmose, Niklas Elmqvist",http://users.umiacs.umd.edu/~elm/projects/vistrates/vistrates.pdf,"Visualization tools are often specialized for specific tasks, which turns the userís analytical workflow into a fragmented process performed across many tools. In this paper, we present a component model design for data visualization to promote modular designs of visualization tools that enhance their analytical scope. Rather than fragmenting tasks across tools, the component model supports unification, where componentsóthe building blocks of this modelócan be assembled to support a wide range of tasks. Furthermore, the model also provides additional key properties, such as support for collaboration, sharing across multiple devices, and adaptive usage depending on expertise, from creating visualizations using dropdown menus, through instantiating components, to actually modifying components or creating entirely new ones from scratch using JavaScript or Python source code. To realize our model, we introduce VISTRATES, a literate computing platform for developing, assembling, and sharing visualization components. From a visualization perspective, Vistrates features cross-cutting components for visual representations, interaction, collaboration, and device responsiveness maintained in a component repository. From a development perspective, Vistrates offers a collaborative programming environment where novices and experts alike can compose component pipelines for specific analytical activities. Finally, we present several Vistrates use cases that span the full range of the classic ìanytimeî and ìanywhereî motto for ubiquitous analysis: from mobile and on-the-go usage, through office settings, to collaborative smart environments covering a variety of tasks and devices.",,https://github.com/karthikbadam/Vistrates,,,vimeo 289784994,,2018,2018,InfoVis,Estrel Hall C,Wednesday,Devices,24-Oct,11:00 AM,11:20 AM,
InfoVis,TVCG,SmartCues: A Multitouch Query Approach for Details-on-Demand through Dynamically Computed Overlays ,J),"Hariharan Subramonyam, Eytan Adar",,,,,,,vimeo 289784720,,2018,2018,InfoVis,Estrel Hall C,Wednesday,Devices,24-Oct,11:20 AM,11:40 AM,
InfoVis,TVCG,"Multiple Coordinated Views at Large Displays for Multiple Users: Empirical Findings on User Behavior, Movements, and Distances ",J),"Ricardo Langner, Ulrike Kister, Raimund Dachselt",,,,,,,vimeo 289784543,,2018,2018,InfoVis,Estrel Hall C,Wednesday,Devices,24-Oct,11:40 AM,12:00 PM,
InfoVis,TVCG,Visualizing Ranges over Time on Mobile Phones: A Task-Based Crowdsourced Evaluation ,J),"Matthew Brehmer, Bongshin Lee, Petra Isenberg, Eun Kyoung Choe",https://hal.inria.fr/hal-01857469/document,"In the first crowdsourced visualization experiment conducted exclusively on mobile phones, we compare approaches to visualizing ranges over time on small displays. People routinely consume such data via a mobile phone, from temperatures in weather forecasting apps to sleep and blood pressure readings in personal health apps. However, we lack guidance on how to effectively visualize ranges on small displays in the context of different value retrieval and comparison tasks, or with respect to different data characteristics such as periodicity, seasonality, or the cardinality of ranges. Central to our experiment is a comparison between two ways to lay out ranges: a more conventional linear layout strikes a balance between quantitative and chronological scale resolution, while a less conventional radial layout emphasizes the cyclicality of time and may prioritize discrimination between values at its periphery. With results from 87 crowd workers, we found that while participants completed tasks more quickly with linear layouts than with radial ones, there were few differences in terms of error rate between layout conditions. We also found that participants performed similarly with both layouts in tasks that involved comparing superimposed observed and average ranges.",,https://github.com/Microsoft/RangesOnMobile/blob/master/StudyApp,https://github.com/Microsoft/RangesOnMobile/blob/master/StudyDataAnalysis,,vimeo 289784625,,2018,2018,InfoVis,Estrel Hall C,Wednesday,Devices,24-Oct,12:00 PM,12:20 PM,
InfoVis,TVCG,Glanceable Visualization: Studies of Data Comparison Performance on Smartwatches ,J),"Tanja Blascheck, Lonni Besan√ßon, Anastasia Bezerianos, Bongshin Lee, Petra Isenberg",https://hal.inria.fr/hal-01851306/file/Blascheck_2018_Glanceable_Visualization.pdf,,,,,,vimeo 289785013,,2018,2018,InfoVis,Estrel Hall C,Wednesday,Devices,24-Oct,12:20 PM,12:40 PM,
CG&A,CGA,Physical Visualization of Geospatial Datasets,,"Hessam Djavaherpour, Ali Mahdavi-Amiri, Faramarz F. Samavati",,,,,,,vimeo 289785692,,2018,2018,Other,Room III,Wednesday,NA,24-Oct,11:00 AM,11:20 AM,
CG&A,CGA,Typology of Uncertainty in Static Geolocated Graphs for Visualization,,"Tatiana von Landesberger, Sebastian Bremm, Marcel Wunderlich",,,,,,,vimeo 289785707,,2018,2018,Other,Room III,Wednesday,NA,24-Oct,11:20 AM,11:40 AM,
CG&A,CGA,Impact of Spatial Scales on the Intercomparison of Climate Scenarios,,"Wei Luo, Michael Steptoe, Zheng Chang, Robert Link, Leon Clarke, Ross Maciejewski",,,,,,,vimeo 289785725,,2018,2018,Other,Room III,Wednesday,NA,24-Oct,11:40 AM,12:00 PM,
CG&A,CGA,Urban Space Explorer: A Visual Analytics System for Urban Planning,,"Alireza Karduni, Isaac Cho, Ginette Wessel, William Ribarsky, Eric Sauda, Wenwen Dou",,,,,,,vimeo 289785751,,2018,2018,Other,Room III,Wednesday,NA,24-Oct,12:00 PM,12:20 PM,
CG&A,CGA,Name Profiler Toolkit,,"Feng Wang, Brett Hansen, Ryan Simmons, Ross Maciejewski",,,,,,,vimeo 289785766,,2018,2018,Other,Room III,Wednesday,NA,24-Oct,12:20 PM,12:40 PM,
VAST,TVCG,"SIRIUS: Dual, Symmetric, Interactive Dimension Reductions ",J),"Michelle Dowling, John Wenskovitch, J.T. Fry, Leanna House, Scotland Leman, Chris North",,,,,,,vimeo 289787667,,2018,2018,VAST,"Convention Hall 1, Section C",Wednesday,High Dimensional Data,24-Oct,2:20 PM,2:40 PM,
TVCG,TVCG,A Perception-Driven Approach to Supervised Dimensionality Reduction for Visualization ,T),"Yunhai Wang, Kang Feng, Xiaowei Chu, Jian Zhang, Chi-Wing Fu, Michael Sedlmair, Xiaohui Yu, Baoquan Chen",,,,,,,vimeo 289788938,,,2018,VAST,"Convention Hall 1, Section C",Wednesday,High Dimensional Data,24-Oct,2:40 PM,3:00 PM,
VAST,VAST,SMARTexplore: Simplifying High-Dimensional Data Analysis through a Table-Based Visual Analytics Approach ,C),"Michael Blumenschein, Michael Behrisch, Stefanie Schmid, Simon Butscher, Deborah R. Wahl, Karoline Villinger, Britta Renner, Harald Reiterer, Daniel Keim",,,,,,,vimeo 289787735,,2018,2018,VAST,"Convention Hall 1, Section C",Wednesday,High Dimensional Data,24-Oct,3:00 PM,3:20 PM,
TVCG,TVCG,ColorMapND: A Data-Driven Approach and Tool for Mapping Multivariate Data to Color ,T),"Shenghui Cheng, Wei Xu, Klaus Mueller",,,,,,,vimeo 289788955,,,2018,VAST,"Convention Hall 1, Section C",Wednesday,High Dimensional Data,24-Oct,3:20 PM,3:40 PM,
VAST,VAST,EmbeddingVis: A Visual Analytics Approach to Comparative Network Embedding Inspection ,C),"Quan Li, Kristanto Sean Njotoprawiro, Hammad Haleem, Qiaoan Chen, Chris YI, Xiaojuan Ma",,,,,,,vimeo 289788000,,2018,2018,VAST,"Convention Hall 1, Section C",Wednesday,High Dimensional Data,24-Oct,3:40 PM,4:00 PM,
InfoVis,TVCG,Evaluating 'Graphical Perception' with CNNs,,"Daniel Haehn, James Tompkin, Hanspeter Pfister",https://github.com/Rhoana/perception/tree/master/PAPER,"Convolutional neural networks can successfully perform many computer vision tasks on images. For visualization, how do CNNs perform when applied to graphical perception tasks? We investigate this question by reproducing Cleveland and McGillís seminal 1984 experiments, which measured human perception efficiency of different visual encodings and defined elementary perceptual tasks for visualization. We measure the graphical perceptual capabilities of four network architectures on five different visualization tasks and compare to existing and new human performance baselines. While under limited circumstances CNNs are able to meet or outperform human task performance, we find that CNNs are not currently a good model for human graphical perception. We present the results of these experiments to foster the understanding of how CNNs succeed and fail when applied to data visualizations.",,https://github.com/rhoana/perception,,,vimeo 280506639,,2018,2018,InfoVis,"Convention Hall 1, Section D",Wednesday,Text & Communication,24-Oct,2:20 PM,2:40 PM,
InfoVis,TVCG,NLIZE: A Perturbation-Driven Visual Interrogation Tool for Analyzing and Interpreting Natural Language Inference Models ,J),"Shusen Liu, Zhimin Li, Tao Li, Vivek Srikumar, Valerio Pascucci, Peer-Timo Bremer",http://www.sci.utah.edu/~shusenl/publications/paper_entailVis.pdf,"With the recent advances in deep learning, neural network models have obtained state-of-the-art performances for many linguistic tasks in natural language processing. However, this rapid progress also brings enormous challenges. The opaque nature of a neural network model leads to hard-to-debug-systems and difficult-to-interpret mechanisms. Here, we introduce a visualization system that, through a tight yet flexible integration between visualization elements and the underlying model, allows a user to interrogate the model by perturbing the input, internal state, and prediction while observing changes in other parts of the pipeline. We use the natural language inference problem as an example to illustrate how a perturbation-driven paradigm can help domain experts assess the potential limitation of a model, probe its inner states, and interpret and form hypotheses about fundamental model mechanisms such as attention.",,,,,vimeo 289784737,,2018,2018,InfoVis,"Convention Hall 1, Section D",Wednesday,Text & Communication,24-Oct,2:40 PM,3:00 PM,
InfoVis,TVCG,Elastic Documents: Coupling Text and Tables through Contextual Visualizations for Enhanced Document Reading ,J),"Sriram Karthik Badam, Zhicheng Liu, Niklas Elmqvist",http://users.umiacs.umd.edu/~elm/projects/elastic-documents/elastic-documents.pdf,"Today's data-rich documents are often complex datasets in themselves, consisting of information in different formats such as text, gures, and data tables. These additional media augment the textual narrative in the document. However, the static layout of a traditional for-print document often impedes deep understanding of its content because of the need to navigate to access content scattered throughout the text. In this paper, we seek to facilitate enhanced comprehension of such documents through a contextual visualization technique that couples text content with data tables contained in the document. We parse the text content and data tables, cross-link the components using a keyword-based matching algorithm, and generate on-demand visualizations based on the reader's current focus within a document. We evaluate this technique in a user study comparing our approach to a traditional reading experience. Results from our study show that (1) participants comprehend the content better with tighter coupling of text and data, (2) the contextual visualizations enable participants to develop better summaries that capture the main data-rich insights within the document, and (3) overall, our method enables participants to develop a more detailed understanding of the document content.",,,,,vimeo 289784966,,2018,2018,InfoVis,"Convention Hall 1, Section D",Wednesday,Text & Communication,24-Oct,3:00 PM,3:20 PM,
InfoVis,TVCG,Augmenting Visualizations with Interactive Data Facts to Facilitate Interpretation and Communication ,J),"Arjun Srinivasan, Steven Drucker, Alex Endert, John Stasko",https://arjun010.github.io/static/papers/voder-infovis18.pdf,"Recently, an increasing number of visualization systems have begun to incorporate natural language generation (NLG) capabilities into their interfaces. NLG-based visualization systems typically leverage a suite of statistical functions to automatically extract key facts about the underlying data and surface them as natural language sentences alongside visualizations. With current systems, users are typically required to read the system-generated sentences and mentally map them back to the accompanying visualization. However, depending on the features of the visualization (e.g., visualization type, data density) and the complexity of the data fact, mentally mapping facts to visualizations can be a challenging task. Furthermore, more than one visualization could be used to illustrate a single data fact. Unfortunately, current tools provide little or no support for users to explore such alternatives. In this paper, we explore how system-generated data facts can be treated as interactive widgets to help users interpret visualizations and communicate their findings. We present Voder, a system that lets users interact with automatically-generated data facts to explore both alternative visualizations to convey a data fact as well as a set of embellishments to highlight a fact within a visualization. Leveraging data facts as interactive widgets, Voder also facilitates data fact-based visualization search. To assess Voderís design and features, we conducted a preliminary user study with 12 participants having varying levels of experience with visualization tools. Participant feedback suggested that interactive data facts aided them in interpreting visualizations. Participants also stated that the suggestions surfaced through the facts helped them explore alternative visualizations and embellishments to communicate individual data facts.",,,,,vimeo 289784943,,2018,2018,InfoVis,"Convention Hall 1, Section D",Wednesday,Text & Communication,24-Oct,3:20 PM,3:40 PM,
InfoVis,TVCG,What Do We Talk About When We Talk About Dashboards? ,J),"Alper Sarikaya, Michael Correll, Lyn Bartram, Melanie Tory, Danyel A Fisher",https://alper.datav.is/assets/publications/dashboards/dashboards-preprint.pdf,"Dashboards are one of the most common use cases for data visualization, and their design and contexts of use are considerably different from exploratory visualization tools. In this paper, we look at the broad scope of how dashboards are used in practice through an analysis of dashboard examples and documentation about their use. We systematically review the literature surrounding dashboard use, construct a design space for dashboards, and identify major dashboard types. We characterize dashboards by their design goals, levels of interaction, and the practices around them. Our framework and literature review suggest a number of fruitful research directions to better support dashboard design, implementation, and use.",,,,,vimeo 289785315,,2018,2018,InfoVis,"Convention Hall 1, Section D",Wednesday,Text & Communication,24-Oct,3:40 PM,4:00 PM,
SciVis,TVCG,Visualization of Bubble Formation in Porous Media ,J),"Hui Zhang, Steffen Frey, Holger Steeb, David Uribe, Thomas Ertl, Wenping Wang",,,,,,,vimeo 290325359,,2018,2018,SciVis,Estrel Hall A+B,Wednesday,Space and Physics,24-Oct,2:20 PM,2:40 PM,
SciVis,TVCG,Gaia Sky: Navigating the Gaia Catalog ,J),"Toni Sagrist√† Sell√©s, Stefan Jordan, Thomas Mueller, Filip Sadlo",,,,,,,vimeo 290325474,,2018,2018,SciVis,Estrel Hall A+B,Wednesday,Space and Physics,24-Oct,2:40 PM,3:00 PM,
SciVis,TVCG,Interactive 3D Visual Analysis of Atmospheric Fronts ,J),"Michael Alexander Kern, Timothy David Hewson, Andreas Sch√§fler, R√ºdiger Westermann, Marc Rautenhaus",,,,,,,vimeo 290325737,,2018,2018,SciVis,Estrel Hall A+B,Wednesday,Space and Physics,24-Oct,3:00 PM,3:20 PM,
SciVis,TVCG,An Interactive Framework for Visualization of Weather Forecast Ensembles ,J),"Bo Ma, Alireza Entezari",,,,,,,vimeo 290325855,,2018,2018,SciVis,Estrel Hall A+B,Wednesday,Space and Physics,24-Oct,3:20 PM,3:40 PM,
TVCG,TVCG,Animation Plans for Before-And-After Satellite images ,T),"Mar√≠a-Jes√∫s Lobo, Caroline Appert, Emmanuel Pietriga",,,,,,,vimeo 289789265,,,2018,SciVis,Estrel Hall A+B,Wednesday,Space and Physics,24-Oct,3:40 PM,4:00 PM,
VAST,TVCG,Vulnus: Visual Vulnerability Analysis for Network Security ,J),"Marco Angelini, Graziano Blasilli, Tiziana Catarci, Simone Lenti, Giuseppe Santucci",,,,,,,vimeo 289787623,,2018,2018,VAST,"Convention Hall 1, Section C",Thursday,"Security, Privacy, and Anomaly",25-Oct,9:00 AM,9:20 AM,
VAST,TVCG,GraphProtector: a Visual Interface for Employing and Assessing Multiple Privacy Preserving Graph Algorithms ,J),"Xumeng Wang, Wei Chen, Huihua Guan, Wenlong Chen, Rusheng Pan, Jia-Kai Chou, Chris Bryan, Kwan-Liu Ma",,,,,,,vimeo 289787471,,2018,2018,VAST,"Convention Hall 1, Section C",Thursday,"Security, Privacy, and Anomaly",25-Oct,9:20 AM,9:40 AM,
VAST,TVCG,Situ: Identifying and explaining suspicious behavior in networks ,J),"John Goodall, Eric Ragan, Chad Steed, Joel Reed, Gregory Richardson, Kelly Huffer, Robert Bridges, Jason Laska",,,,,,,vimeo 289787635,,2018,2018,VAST,"Convention Hall 1, Section C",Thursday,"Security, Privacy, and Anomaly",25-Oct,9:40 AM,10:00 AM,
VAST,TVCG,A Visual Analytics Framework for the Detection of Anomalous Call Stack Trees in High Performance Computing Applications ,J),"Cong Xie, Wei Xu, Klaus Mueller",,,,,,,vimeo 289787924,,2018,2018,VAST,"Convention Hall 1, Section C",Thursday,"Security, Privacy, and Anomaly",25-Oct,10:00 AM,10:20 AM,
VAST,TVCG,Lessons Learned Developing a Visual Analytics Solution for Investigative Analysis of Scamming Activities ,J),"Jay Koven, Cristian Felix, Hossein Siadati, Enrico Bertini, Markus Jakobsson",,,,,,,vimeo 289787515,,2018,2018,VAST,"Convention Hall 1, Section C",Thursday,"Security, Privacy, and Anomaly",25-Oct,10:20 AM,10:40 AM,
InfoVis,TVCG,Origin-Destination Flow Maps in Immersive Environments ,J),"Yalong Yang, Tim Dwyer, Bernhard Jenny, Kim Marriott, Maxime Cordeil, Haohui Chen",https://vis.yalongyang.com/papers/flow-maps-ia.pdf,"Immersive virtual- and augmented-reality headsets can overlay a flat image against any surface or hang virtual objects in the space around the user. The technology is rapidly improving and may, in the long term, replace traditional flat panel displays in many situations. When displays are no longer intrinsically flat, how should we use the space around the user for abstract data visualisation? In this paper, we ask this question with respect to origin-destination flow data in a global geographic context. We report on the findings of three studies exploring different spatial encodings for flow maps. The first experiment focuses on different 2D and 3D encodings for flows on flat maps. We find that participants are significantly more accurate with raised flow paths whose height is proportional to flow distance but fastest with traditional straight line 2D flows. In our second and third experiment we compared flat maps, 3D globes and a novel interactive design we call <i>MapsLink</i>, involving a pair of linked flat maps. We find that participants took significantly more time with MapsLink than other flow maps while the 3D globe with raised flows was the fastest, most accurate, and most preferred method. Our work suggests that <i>careful</i> use of the third spatial dimension can resolve visual clutter in complex flow maps.",,,,,video https://vis.yalongyang.com/videos/vr_flow_maps.mp4,,2018,2018,InfoVis,"Convention Hall 1, Section D",Thursday,Immersive Analytics,25-Oct,9:00 AM,9:20 AM,
InfoVis,TVCG,FiberClay: Sculpting Three Dimensional Trajectories to Reveal Structural Insights ,J),"Christophe Hurter, Nathalie Henry Riche, Steven Drucker, Maxime Cordeil, Richard Alligier, Romain Vuillemot",https://recherche.enac.fr/~hurter/FiberClay/FiberClay2018.pdf,"Visualizing 3D trajectories to extract insights about their similarities and spatial configuration is a critical task in several domains. Air traffic controllers for example deal with large quantities of aircrafts routes to optimize safety in airspace and neuroscientists attempt to understand neuronal pathways in the human brain by visualizing bundles of fibers from DTI images. Extracting insights from masses of 3D trajectories is challenging as the multiple three dimensional lines have complex geometries, may overlap, cross or even merge with each other, making it impossible to follow individual ones in dense areas. As trajectories are inherently spatial and three dimensional, we propose FiberClay: a system to display and interact with 3D trajectories in immersive environments. FiberClay renders a large quantity of trajectories in real time using GP-GPU techniques. FiberClay also introduces a new set of interactive techniques for composing complex queries in 3D space leveraging immersive environment controllers and user position. These techniques enable an analyst to select and compare sets of trajectories with specific geometries and data properties. We conclude by discussing insights found using FiberClay with domain experts in air traffic control and neurology.",,,,,vimeo 289784766,,2018,2018,InfoVis,"Convention Hall 1, Section D",Thursday,Immersive Analytics,25-Oct,9:20 AM,9:40 AM,
InfoVis,TVCG,DXR: A Toolkit for Building Immersive Data Visualizations ,J),"Ronell Sicat, Jiabao Li, JunYoung Choi, Maxime Cordeil, Won-Ki Jeong, Benjamin Bach, Hanspeter Pfister",,,,,,,youtube p4fB_OfoaZA,,2018,2018,InfoVis,"Convention Hall 1, Section D",Thursday,Immersive Analytics,25-Oct,9:40 AM,10:00 AM,
InfoVis,TVCG,Information Olfactation: Harnessing Scent to Convey Data ,J),"Biswaksen Patnaik, Andrea Batch, Niklas Elmqvist",http://users.umiacs.umd.edu/~elm/projects/info-olfac/info-olfac.pdf,"Olfactory feedback for analytical tasks is a virtually unexplored area in spite of the advantages it offers for information recall, feature identification, and location detection. Here we introduce the concept of information olfactation as the fragrant sibling of information visualization, and discuss how scent can be used to convey data. Building on a review of the human olfactory system and mirroring common visualization practice, we propose olfactory marks, the substrate in which they exist, and their olfactory channels that are available to designers. To exemplify this idea, we present VISCENT: A six-scent stereo olfactory display capable of conveying olfactory glyphs of varying temperature and direction, as well as a corresponding software system that integrates the display with a traditional visualization display. Finally, we present three applications that make use of the viScent system: A 2D graph visualization, a 2D line and point chart, and an immersive analytics graph visualization in 3D virtual reality. We close the paper with a review of possible extensions of viScent and applications of information olfactation for general visualization beyond the examples in this paper.",,,,,vimeo 289784509,,2018,2018,InfoVis,"Convention Hall 1, Section D",Thursday,Immersive Analytics,25-Oct,10:00 AM,10:20 AM,
InfoVis,TVCG,Dynamic Composite Data Physicalization Using Wheeled Micro-Robots ,J),"Mathieu Le Goc, Charles Perin, Sean Follmer, Jean-Daniel Fekete, Pierre Dragicevic",https://hal.inria.fr/hal-01848436/document,"This paper introduces dynamic composite physicalizations, a new class of physical visualizations that use collections of self-propelled objects to represent data. Dynamic composite physicalizations can be used both to give physical form to well-known interactive visualization techniques, and to explore new visualizations and interaction paradigms. We first propose a design space characterizing composite physicalizations based on previous work in the fields of Information Visualization and Human Computer Interaction. We illustrate dynamic composite physicalizations in two scenarios demonstrating potential benefits for collaboration and decision making, as well as new opportunities for physical interaction. We then describe our implementation using wheeled micro-robots capable of locating themselves and sensing user input, before discussing limitations and opportunities for future work.",,,,,vimeo 289784806,,2018,2018,InfoVis,"Convention Hall 1, Section D",Thursday,Immersive Analytics,25-Oct,10:20 AM,10:40 AM,
SciVis,TVCG,Robust and Fast Extraction of 3D Symmetric Tensor Field Topology ,J),"Lawrence Roy, Prashant Kumar, Yue Zhang, Eugene Zhang",,,,,,,vimeo 290325698,,2018,2018,SciVis,Estrel Hall A+B,Thursday,Tensors,25-Oct,9:00 AM,9:20 AM,
SciVis,TVCG,DT-MRI Streamsurfaces Revisited ,J),"Michael Ankele, Thomas Schultz",,,,,,,vimeo 290327825,,2018,2018,SciVis,Estrel Hall A+B,Thursday,Tensors,25-Oct,9:20 AM,9:40 AM,
SciVis,TVCG,Tensor Field Visualization using Fiber Surfaces of Invariant Space ,J),"Felix Raith, Christian Blecha, Thomas Nagel, Francesco Parisio, Olaf Kolditz, Fabian G√ºnther, Markus Stommel, Gerik Scheuermann",,,,,,,vimeo 290327914,,2018,2018,SciVis,Estrel Hall A+B,Thursday,Tensors,25-Oct,9:40 AM,10:00 AM,
TVCG,TVCG,Tensor Decompositions for Integral Histogram Compression and Look-Up ,T),"Rafael Ballester-Ripoll, Renato Pajarola",,,,,,,vimeo 289788992,,,2018,SciVis,Estrel Hall A+B,Thursday,Tensors,25-Oct,10:00 AM,10:20 AM,
VAST,TVCG,An Interactive Method to Improve Crowdsourced Annotations ,J),"Changjian Chen, Shixia Liu, Yafeng Lu, Fangxin Ouyang, Bin Wang",,,,,,,vimeo 289787374,,2018,2018,VAST,Estrel Hall C,Thursday,Interactive Analytics and Design,25-Oct,9:00 AM,9:20 AM,
VAST,TVCG,RegressionExplorer: Interactive Exploration of Logistic Regression Models with Subgroup Analysis ,J),"Dennis Dingen, Marcel van 't Veer, Patrick Houthuizen, Eveline H. J. Mestrom, Erik H.H.M. Korsten, Arthur R.A. Bouwman, Jarke van Wijk",,,,,,,vimeo 289787606,,2018,2018,VAST,Estrel Hall C,Thursday,Interactive Analytics and Design,25-Oct,9:20 AM,9:40 AM,
VAST,TVCG,Drag and Track:  A Direct Manipulation Interface for Contextualizing Data Instances within a Continuous Parameter Space ,J),"Daniel Orban, Daniel Keefe, Ayan Biswas, James Ahrens, David Rogers",,,,,,,vimeo 289787986,,2018,2018,VAST,Estrel Hall C,Thursday,Interactive Analytics and Design,25-Oct,9:40 AM,10:00 AM,
VAST,TVCG,Clustrophile 2: Guided Visual Clustering Analysis ,J),"Marco Cavallo, √áagatay Demiralp",,,,,,,vimeo 289787185,,2018,2018,VAST,Estrel Hall C,Thursday,Interactive Analytics and Design,25-Oct,10:00 AM,10:20 AM,
VAST,TVCG,InkPlanner: Supporting Prewriting via Intelligent Visual Diagramming ,J),"Zhicong Lu, Mingming Fan, Yun Wang, Jian Zhao, Michelle Annett, Daniel Wigdor",,,,,,,vimeo 289787883,,2018,2018,VAST,Estrel Hall C,Thursday,Interactive Analytics and Design,25-Oct,10:20 AM,10:40 AM,
TVCG,TVCG,Visual Analytics in Deep Learning: An Interrogative Survey for the Next Frontiers ,T),"Fred Hohman, Minsuk Kahng, Robert Pienta, Duen Horng Chau",,,,,,,vimeo 289789596,,,2018,VAST,"Convention Hall 1, Section C",Thursday,Deep Learning,25-Oct,11:00 AM,11:20 AM,
VAST,VAST,Analyzing the Noise Robustness of Deep Neural Networks ,C),"Mengchen Liu, Shixia Liu, Hang Su, Kelei Cao, Jun Zhu",,,,,,,vimeo 289787703,,2018,2018,VAST,"Convention Hall 1, Section C",Thursday,Deep Learning,25-Oct,11:20 AM,11:40 AM,
VAST,TVCG,DQNViz: A Visual Analytics Approach to Understand Deep Q-Networks ,J),"Junpeng Wang, Liang Gou, Han-Wei Shen, Hao Yang",,,,,,,vimeo 289787246,,2018,2018,VAST,"Convention Hall 1, Section C",Thursday,Deep Learning,25-Oct,11:40 AM,12:00 PM,
VAST,TVCG,RetainVis: Visual Analytics with Interpretable and Interactive Recurrent Neural Network on Electronic Medical Records ,J),"Bum Chul Kwon, Min-Je Choi, Joanne Kim, Edward Choi, Young Bin Kim, Soonwook Kwon, Jimeng Sun, Jaegul Choo",,,,,,,vimeo 289787946,,2018,2018,VAST,"Convention Hall 1, Section C",Thursday,Deep Learning,25-Oct,12:00 PM,12:20 PM,
VAST,TVCG,GAN Lab: Understanding Complex Deep Generative Models using Interactive Visual Experimentation ,J),"Minsuk Kahng, Nikhil Thorat, Duen Horng Chau, Fernanda Viegas, Martin Wattenberg",,,,,,,vimeo 289787794,,2018,2018,VAST,"Convention Hall 1, Section C",Thursday,Deep Learning,25-Oct,12:20 PM,12:40 PM,
InfoVis,TVCG,A Framework for Creative Visualization-Opportunities Workshops ,J),"Ethan Kerzner, Sarah Goodwin, Jason Dykes, Sara V Jones, Miriah Meyer",http://sci.utah.edu/~vdl/papers/2018_infovis_creative-workshops.pdf,"Applied visualization researchers often work closely with domain collaborators to explore new and useful applications of visualization. The early stages of collaborations are typically time consuming for all stakeholders as researchers piece together an understanding of domain challenges from disparate discussions and meetings. A number of recent projects, however, report on the use of creative visualization-opportunities (CVO) workshops to accelerate the early stages of applied work, eliciting a wealth of requirements in a few days of focused work. Yet, there is no established guidance for how to use such workshops effectively. In this paper, we present the results of a 2-year collaboration in which we analyzed the use of 17 workshops in 10 visualization contexts. Its primary contribution is a framework for CVO workshops that: 1) identifies a process model for using workshops; 2) describes a structure of what happens within effective workshops; 3) recommends 25 actionable guidelines for future workshops; and 4) presents an example workshop and workshop methods. The creation of this framework exemplifies the use of critical reflection to learn about visualization in practice from diverse studies and experience.",,,,,vimeo 289784415,,2018,2018,InfoVis,"Convention Hall 1, Section D",Thursday,Design & Storytelling,25-Oct,11:00 AM,11:20 AM,
TVCG,TVCG,ATOM: A Grammar for Unit Visualizations ,T),"Deokgun Park, Steven M. Drucker, Roland Fernandez, Niklas Elmqvist",,,,,,,vimeo 289789243,,,2018,InfoVis,"Convention Hall 1, Section D",Thursday,Design & Storytelling,25-Oct,11:20 AM,11:40 AM,
InfoVis,TVCG,Design Exposition with Literate Visualization ,J),"Jo Wood, Alexander Kachkaev, Jason Dykes",http://openaccess.city.ac.uk/20081/1/wood_literate_2018.pdf,"We propose a new approach to the visualization design and communication process, literate visualization, based upon and extending, Donald Knuthís idea of literate programming. It integrates the process of writing data visualization code with description of the design choices that led to the implementation (design exposition). We develop a model of design exposition characterised by four visualization designer architypes: the evaluator, the autonomist, the didacticist and the rationalist. The model is used to justify the key characteristics of literate visualization: ënotebookí documents that integrate live coding input, rendered output and textual narrative; low cost of authoring textual narrative; guidelines to encourage structured visualization design and its documentation. We propose narrative schemas for structuring and validating a wide range of visualization design approaches and models, and branching narratives for capturing alternative designs and design views. We describe a new open source literate visualization environment, litvis, based on a declarative interface to Vega and Vega-Lite through the functional programming language Elm combined with markdown for formatted narrative. We informally assess the approach, its implementation and potential by considering three examples spanning a range of design abstractions: new visualization idioms; validation though visualization algebra; and feminist data visualization. We argue that the rich documentation of the design process provided by literate visualization offers the potential to improve the validity of visualization design and so benefit both academic visualization and visualization practice.",,https://github.com/gicentre/litvis,,,vimeo 289785349,,2018,2018,InfoVis,"Convention Hall 1, Section D",Thursday,Design & Storytelling,25-Oct,11:40 AM,12:00 PM,
InfoVis,TVCG,iStoryline: Effective Convergence to Hand-drawn Storylines ,J),"Tan Tang, Sadia Rubab, Jiewen Lai, Weiwei Cui, Lingyun Yu, Yingcai Wu",http://zjuvis.org/files/istoryline.pdf,"Storyline visualization techniques have progressed significantly to generate illustrations of complex stories automatically. However, the visual layouts of storylines are not enhanced accordingly despite the improvement in the performance and extension of its application area. Existing methods attempt to achieve several shared optimization goals, such as reducing empty space and minimizing line crossings and wiggles. However, these goals do not always produce optimal results when compared to hand-drawn storylines. We conducted a preliminary study to learn how users translate a narrative into a hand-drawn storyline and check whether the visual elements in hand-drawn illustrations can be mapped back to appropriate narrative contexts. We also compared the hand-drawn storylines with storylines generated by the state-of-the-art methods and found they have significant differences. Our findings led to a design space that summarizes 1) how artists utilize narrative elements and 2) the sequence of actions artists follow to portray expressive and attractive storylines. We developed iStoryline, an authoring tool for integrating high-level user interactions into optimization algorithms and achieving a balance between hand-drawn storylines and automatic layouts. iStoryline allows users to create novel storyline visualizations easily according to their preferences by modifying the automatically generated layouts. The effectiveness and usability of iStoryline are studied with qualitative evaluations",https://istoryline.github.io/,,https://istoryline.github.io/interview/interview.html,,video https://istoryline.github.io/img/iStoryline.mp4,,2018,2018,InfoVis,"Convention Hall 1, Section D",Thursday,Design & Storytelling,25-Oct,12:00 PM,12:20 PM,
InfoVis,TVCG,Narvis: Authoring Narrative Slideshows for Introducing Data Visualization Designs ,J),"Qianwen Wang, Zhen Li, Siwei Fu, Weiwei Cui, Huamin Qu",https://wangqianwen0418.github.io/assets/pdf/Narvis.pdf,"Visual designs can be complex in modern data visualization systems, which poses special challenges for explaining them to the non-experts. However, few if any presentation tools are tailored for this purpose. In this study, we present Narvis, a slideshow authoring tool designed for introducing data visualizations to non-experts. Narvis targets two types of end users: teachers, experts in data visualization who produce tutorials for explaining a data visualization, and students, non-experts who try to understand visualization designs through tutorials. We present an analysis of requirements through close discussions with the two types of end users. The resulting considerations guide the design and implementation of Narvis. Additionally, to help teachers better organize their introduction slideshows, we specify a data visualization as a hierarchical combination of components, which are automatically detected and extracted by Narvis. The teachers craft an introduction slideshow through first organizing these components, and then explaining them sequentially. A series of templates are provided for adding annotations and animations to improve efficiency during the authoring process. We evaluate Narvis through a qualitative analysis of the authoring experience, and a preliminary evaluation of the generated slideshows.",,,,,vimeo 289784711,,2018,2018,InfoVis,"Convention Hall 1, Section D",Thursday,Design & Storytelling,25-Oct,12:20 PM,12:40 PM,
SciVis,TVCG,Culling for Extreme-Scale Segmentation Volumes: A Hybrid Deterministic and Probabilistic Approach ,J),"Johanna Beyer, Haneen Mohammed, Marco Agus, Ali K. Al-Awami, Hanspeter Pfister, Markus Hadwiger",,,,,,,vimeo 290327965,,2018,2018,SciVis,Estrel Hall A+B,Thursday,Scalable Techniques,25-Oct,11:00 AM,11:20 AM,
SciVis,TVCG,CPU Iso-surface Ray Tracing of Adaptive Mesh Refinement Data ,J),"Feng Wang, Ingo Wald, Qi Wu, Will Usher, Chris R. Johnson",,,,,,,vimeo 290328099,,2018,2018,SciVis,Estrel Hall A+B,Thursday,Scalable Techniques,25-Oct,11:20 AM,11:40 AM,
TVCG,TVCG,Efficient Local Statistical Analysis via Point-Wise Histograms in Tetrahedral Meshes and Curvilinear Grids ,T),"Bo Zhou, Yi-Jen Chiang, Cong Wang",,,,,,,vimeo 289789310,,,2018,SciVis,Estrel Hall A+B,Thursday,Scalable Techniques,25-Oct,11:40 AM,12:00 PM,
TVCG,TVCG,Shadow Accrual Maps: Efficient Accumulation of City-Scale Shadows over Time ,T),"Fabio Miranda, Harish Doraiswamy, Marcos Lage, Luc Wilson, Mondrian Hsieh, Claudio T. Silva",,,,,,,vimeo 289789412,,,2018,SciVis,Estrel Hall A+B,Thursday,Scalable Techniques,25-Oct,12:00 PM,12:20 PM,
TVCG,TVCG,A Scalable Hybrid Scheme for Ray-Casting of Unstructured Volume Data ,T),"Roba Binyahib, Tom Peterka, Matthew Larsen, Kwan-Liu Ma, Hank Childs",,,,,,,vimeo 289789339,,,2018,SciVis,Estrel Hall A+B,Thursday,Scalable Techniques,25-Oct,12:20 PM,12:40 PM,
InfoVis,TVCG,Charticulator: Interactive Construction of Bespoke Chart Layouts ,J),"Donghao Ren, Bongshin Lee, Matthew Brehmer",https://donghaoren.org/publications/infovis18-charticulator.pdf,"We present Charticulator, an interactive authoring tool that enables the creation of bespoke and reusable chart layouts. Charticulator is our response to most existing chart construction interfaces that require authors to choose from predefined chart layouts, thereby precluding the construction of novel charts. In contrast, Charticulator transforms a chart specification into mathematical layout constraints and automatically computes a set of layout attributes using a constraint-solving algorithm to realize the chart. It allows for the articulation of compound marks or glyphs as well as links between these glyphs, all without requiring any coding or knowledge of constraint satisfaction. Furthermore, thanks to the constraint-based layout approach, Charticulator can export chart designs into reusable templates that can be imported into other visualization tools. In addition to describing Charticulatorís conceptual framework and design, we present three forms of evaluation: a gallery to illustrate its expressiveness, a user study to verify its usability, and a click-count comparison between Charticulator and three existing tools. Finally, we discuss the limitations and potentials of Charticulator as well as directions for future research. Charticulator is available with its source code at https://charticulator.com.",https://charticulator.com/app/index.html,https://github.com/Microsoft/charticulator,,,video https://charticulator.azureedge.net/videos/charticulator-supplemental.mp4,,2018,2018,InfoVis,Estrel Hall C,Thursday,Interaction,25-Oct,11:00 AM,11:20 AM,
InfoVis,TVCG,Embedded Merge & Split: Visual Adjustment of Data Grouping ,J),"Ali Sarvghad, Bahador Saket, Alex Endert, Nadir Weibel",http://bahadorsaket.com/publication/EMS.pdf,"Data grouping is among the most frequently used operations in data visualization. It is the process through which relevant information is gathered, simplified, and expressed in summary form. Many popular visualization tools support automatic grouping of data (e.g., dividing up a numerical variable into bins). Although grouping plays a pivotal role in supporting data exploration, further adjustment and customization of auto-generated grouping criteria is non-trivial. Such adjustments are currently performed either programmatically or through menus and dialogues which require specific parameter adjustments over several steps. In response, we introduce Embedded Merge & Split (EMS), a new interaction technique for direct adjustment of data grouping criteria. We demonstrate how the EMS technique can be designed to directly manipulate width and position in bar charts and histograms, as a means for adjustment of data grouping criteria. We also offer a set of design guidelines for supporting EMS. Finally, we present the results of two user studies, providing initial evidence that EMS can significantly reduce interaction time compared to WIMP-based technique and was subjectively preferred by participants.",,,,,youtube Z2rL6WF6TLY,,2018,2018,InfoVis,Estrel Hall C,Thursday,Interaction,25-Oct,11:20 AM,11:40 AM,
TVCG,TVCG,Smart Brushing for Parallel Coordinates ,T),"Richard Roberts, Robert S Laramee, Gary A Smith, Paul Brookes, Tony D'Cruze",http://cs.swan.ac.uk/~csbob/research/callCenter/brushing/roberts18smart.pdf,"The Parallel Coordinates plot is a popular tool for the visualization of high-dimensional data. One of the main challenges when using parallel coordinates is occlusion and overplotting resulting from large data sets. Brushing is a popular approach to address these challenges. Since its conception, limited improvements have been made to brushing both in the form of visual design and functional interaction. We present a set of novel, smart brushing techniques that enhance the standard interactive brushing of a parallel coordinates plot. We introduce two new interaction concepts: Higher-order, sketch-based brushing, and smart, data-driven brushing. Higher-order brushes support interactive, flexible, n-dimensional pattern searches involving an arbitrary number of dimensions. Smart, data-driven brushing provides interactive, real-time guidance to the user during the brushing process based on derived meta-data. In addition, we implement a selection of novel enhancements and user options that complement the two techniques as well as enhance the exploration and analytical ability of the user. We demonstrate the utility and evaluate the results using a case study with a large, high-dimensional, real-world telecommunication data set and we report domain expert feedback from the data suppliers.",,,,,vimeo 289789480,,,2018,InfoVis,Estrel Hall C,Thursday,Interaction,25-Oct,11:40 AM,12:00 PM,
TVCG,TVCG,"Multidimensional Projection for Visual Analytics: Linking Techniques with Distortions, Tasks, and Layout Enrichment ",T),Luis Gustavo Nonato and Michael Aupetit,http://www.lcad.icmc.usp.br/~nonato/pubs/mdp-survey.pdf,"Visual analysis of multidimensional data requires expressive and effective ways to reduce data dimensionality to encode them visually. Multidimensional projections (MDP) figure among the most important visualization techniques in this context, transforming multidimensional data into scatter plots whose visual patterns reflect some notion of similarity in the original data. However, MDP come with distortions that make these visual patterns not trustworthy, hindering users to infer actual data characteristics. Moreover, the patterns present in the scatter plots might not be enough to allow a clear understanding of multidimensional data, motivating the development of layout enrichment methodologies to operate together with MDP. This survey attempts to cover the main aspects of MDP as a visualization and visual analytic tool. It provides detailed analysis and taxonomies as to the organization of MDP techniques according to their main properties and traits, discussing the impact of such properties for visual perception and other human factors. The survey also approaches the different types of distortions that can result from MDP mappings and it overviews existing mechanisms to quantitatively evaluate such distortions. A qualitative analysis of the impact of distortions on the different analytic tasks performed by users when exploring multidimensional data through MDP is also presented. Guidelines for choosing the best MDP for an intended task are also provided as a result of this analysis. Finally, layout enrichment schemes to debunk MDP distortions and/or reveal relevant information not directly inferable from the scatter plot are reviewed and discussed in the light of new taxonomies. We conclude the survey providing future research axes to fill discovered gaps in this domain.",,,,,vimeo 289789153,,,2018,InfoVis,Estrel Hall C,Thursday,Interaction,25-Oct,12:00 PM,12:20 PM,
TVCG,TVCG,Exploration Strategies for Discovery of Interactivity in Visualizations ,T),"Tanja Blascheck, Lindsay MacDonald Vermeulen, Jo Vermeulen, Charles Perin, Wesley Willett, Thomas Ertl, Sheelagh Carpendale",https://hal.archives-ouvertes.fr/hal-01705792/document,"We investigate how people discover the functionality of an interactive visualization that was designed for the general public. While interactive visualizations are increasingly available for public use, we still know little about how the general public discovers what they can do with these visualizations and what interactions are available. Developing a better understanding of this discovery process can help inform the design of visualizations for the general public, which in turn can help make data more accessible. To unpack this problem, we conducted a lab study in which participants were free to use their own methods to discover the functionality of a connected set of interactive visualizations of public energy data. We collected eye movement data and interaction logs as well as video and audio recordings. By analyzing this combined data, we extract exploration strategies that the participants employed to discover the functionality in these interactive visualizations. These exploration strategies illuminate possible design directions for improving the discoverability of a visualizationís functionality.",,,http://innovis.cpsc.ucalgary.ca/supplemental/Exploration-Strategies/#data,,vimeo 289789025,,,2018,InfoVis,Estrel Hall C,Thursday,Interaction,25-Oct,12:20 PM,12:40 PM,
CG&A,CGA,OpenSpace: Changing the Narrative of Public Dissemination in Astronomical Visualization from What to How,,"Alexander Bock, Emil Axelsson, Carter Emmart, Masha Kuznetsova, Charles Hansen, Anders Ynnerman",,,,,,,vimeo 289785793,,2018,2018,Other,Room III,Thursday,NA,25-Oct,11:00 AM,11:20 AM,
CG&A,CGA,Belle2VR: A Virtual-Reality Visualization of Subatomic Particle Physics in the Belle II Experiment,,"Zach Duer, Leo Piilonen, and George Glasson",,,,,,,vimeo 289785809,,2018,2018,Other,Room III,Thursday,NA,25-Oct,11:20 AM,11:40 AM,
CG&A,CGA,Application-Driven Design: Help Students Understand Employment and See the ‚ÄúBig Picture‚Äù,,"Li Liu, Deborah Silver, Karen Bemis",,,,,,,vimeo 289785826,,2018,2018,Other,Room III,Thursday,NA,25-Oct,11:40 AM,12:00 PM,
CG&A,CGA,Management of Cerebral Aneurysm Descriptors based on an Automatic Ostium Extraction,,"Monique Meuschke, Tobias G√ºnther, Ralph Wickenh√∂fer, Markus Gross, Bernhard Preim, Kai Lawonn",,,,,,,vimeo 289785840,,2018,2018,Other,Room III,Thursday,NA,25-Oct,12:00 PM,12:20 PM,
CG&A,CGA,Toward a Multimodal Diagnostic Exploratory Visualization of Focal Cortical Dysplasia,,"Shin-Ting Wu, Raphael Voltoline, Wallace S. Loos, J.A. Iv√°n Rubianes, Lionis S. Watanabe, B√°rbara J. Amorim, A. Carolina Coan, Fernando Cendes, Clarissa L. Yasuda",,,,,,,vimeo 289785856,,2018,2018,Other,Room III,Thursday,NA,25-Oct,12:20 PM,12:40 PM,
VAST,TVCG,ViBr: Visualizing Bipartite Relations at Scale with the Minimum Description Length Principle ,J),"Gromit Yeuk-Yin Chan, Panpan Xu, Zeng Dai, Liu Ren",,,,,,,vimeo 289787354,,2018,2018,VAST,"Convention Hall 1, Section C",Thursday,Graph and Image,25-Oct,2:20 PM,2:40 PM,
VAST,VAST,Segue: Overviewing Evolution Patterns of Egocentric Networks by Interactive Construction of Spatial Layouts ,C),"Po-Ming Law, Yanhong Wu, Rahul Basole",,,,,,,vimeo 289788023,,2018,2018,VAST,"Convention Hall 1, Section C",Thursday,Graph and Image,25-Oct,2:40 PM,3:00 PM,
VAST,TVCG,A Visual Analytics Framework for Spatiotemporal Trade Network Analysis ,J),"Hong Wang, Yafeng Lu, Shade Shutters, Michael Steptoe, Feng Wang, Steven Landis, Ross Maciejewski",,,,,,,vimeo 289787400,,2018,2018,VAST,"Convention Hall 1, Section C",Thursday,Graph and Image,25-Oct,3:00 PM,3:20 PM,
TVCG,TVCG,A Semantic-based Method for Visualizing Large Image Collections ,T),"Xiao Xie, Xiwen Cai, Junpei Zhou, Nan Cao, Yingcai Wu",,,,,,,vimeo 289789441,,,2018,VAST,"Convention Hall 1, Section C",Thursday,Graph and Image,25-Oct,3:20 PM,3:40 PM,
TVCG,TVCG,PhotoRecomposer: Interactive Photo Recomposition by Cropping ,T),"Yuan Liang, Xiting Wang, Song-Hai Zhang, Shi-Min Hu, Shixia Liu",,,,,,,vimeo 289788924,,,2018,VAST,"Convention Hall 1, Section C",Thursday,Graph and Image,25-Oct,3:40 PM,4:00 PM,
InfoVis,TVCG,Mapping Color to Meaning in Colormap Data Visualizations ,J),"Karen B. Schloss, Connor C. Gramazio, Allison T. Silverman, Madeline L. Parker, Audrey S. Wang",https://schlosslab.discovery.wisc.edu/wp-content/uploads/2018/09/SchlossGramazioSilvermanParkerWanginPress.pdf,"To interpret data visualizations, people must determine how visual features map onto concepts. For example, to interpret colormaps, people must determine how dimensions of color (e.g., lightness, hue) map onto quantities of a given measure (e.g., brain activity, correlation magnitude). This process is easier when the encoded mappings in the visualization match peopleís predictions of how visual features will map onto concepts, their inferred mappings. To harness this principle in visualization design, it is necessary to understand what factors determine peopleís <i>inferred mappings</i>. In this study, we investigated how inferred color-quantity mappings for colormap data visualizations were influenced by the background color. Prior literature presents seemingly conflicting accounts of how the background color affects inferred color-quantity mappings. The present results help resolve those conflicts, demonstrating that sometimes the background has an effect and sometimes it does not, depending on whether the colormap appears to vary in opacity. When there is no apparent variation in opacity, participants infer that darker colors map to larger quantities (<i>dark-is-more bias</i>). As apparent variation in opacity increases, participants become biased toward inferring that more opaque colors map to larger quantities (<i>opaque-is-more bias</i>). These biases work together on light backgrounds and conflict on dark backgrounds. Under such conflicts, the opaque-is-more bias can negate, or even supersede the dark-is-more bias. The results suggest that if a design goal is to produce colormaps that match peopleís inferred mappings and are robust to changes in background color, it is beneficial to use colormaps that will not appear to vary in opacity on any background color, and to encode larger quantities in darker colors.",,,https://schlosslab.discovery.wisc.edu/resources/,,vimeo 289784916,,2018,2018,InfoVis,"Convention Hall 1, Section D",Thursday,Perception & Cognition 1,25-Oct,2:20 PM,2:40 PM,
InfoVis,TVCG,Optimizing Color Assignment for Perception of Class Separability in Multiclass Scatterplots ,J),"Yunhai Wang, Xin Chen, Tong Ge, Chen Bao, Michael Sedlmair, Chi-Wing Fu, Oliver Deussen, Baoquan Chen",http://www.yunhaiwang.org/infovis18/color/vis-color.pdf,"Appropriate choice of colors significantly aids viewers in understanding the structures in multiclass scatterplots and becomes more important with a growing number of data points and groups. An appropriate color mapping is also an important parameter for the creation of an aesthetically pleasing scatterplot. Currently, users of visualization software routinely rely on color mappings that have been pre-defined by the software. A default color mapping, however, cannot ensure an optimal perceptual separability between groups, and sometimes may even lead to a misinterpretation of the data. In this paper, we present an effective approach for color assignment based on a set of given colors that is designed to optimize the perception of scatterplots. Our approach takes into account the spatial relationships, density, degree of overlap between point clusters, and also the background color. For this purpose, we use a genetic algorithm that is able to efficiently find good color assignments. We implemented an interactive color assignment system with three extensions of the basic method that incorporates top K suggestions, user-defined color subsets, and classes of interest for the optimization. To demonstrate the effectiveness of our assignment technique, we conducted a numerical study and a controlled user study to compare our approach with default color assignments; our findings were verified by two expert studies. The results show that our approach is able to support users in distinguishing cluster numbers faster and more precisely than default assignment methods.",http://www.color-assignment.net/,,,,vimeo 289785222,,2018,2018,InfoVis,"Convention Hall 1, Section D",Thursday,Perception & Cognition 1,25-Oct,2:40 PM,3:00 PM,
InfoVis,TVCG,Looks Good To Me: Visualizations As Sanity Checks ,J),"Michael Correll, Mingwei Li, Gordon L Kindlmann, Carlos Scheidegger",https://github.com/AlgebraicVis/SanityCheck/blob/master/InfoVis/preprint.pdf,"Famous examples such as Anscombeís Quartet highlight that one of the core benefits of visualizations is allowing people to discover visual patterns that might otherwise be hidden by summary statistics. This visual inspection is particularly important in exploratory data analysis, where analysts can use visualizations such as histograms and dot plots to identify data quality issues. Yet, these visualizations are driven by parameters such as histogram bin size or mark opacity that have a great deal of impact on the final visual appearance of the chart, but are rarely optimized to make important features visible. In this paper, we show that data flaws have varying impact on the visual features of visualizations, and that the adversarial or merely uncritical setting of design parameters of visualizations can obscure the visual signatures of these flaws. Drawing on the framework of Algebraic Visualization Design, we present the results of a crowdsourced study showing that common visualization types can appear to reasonably summarize distributional data while hiding large and important flaws such as missing data and extraneous modes. We make use of these results to propose additional best practices for visualizations of distributions for data quality tasks.",https://medium.com/@mcorrell/looks-good-to-me-visualizations-as-sanity-checks-6fd1ffa37ab9,https://github.com/AlgebraicVis/SanityCheck/tree/master/study,https://github.com/AlgebraicVis/SanityCheck/tree/master/study/data,,vimeo 289785290,,2018,2018,InfoVis,"Convention Hall 1, Section D",Thursday,Perception & Cognition 1,25-Oct,3:00 PM,3:20 PM,
TVCG,TVCG,Is There a Robust Technique for Selecting Aspect Ratios in Line Charts? ,T),"Yunhai Wang, Zeyu Wang, Lifeng Zhu, Jian Zhang, Chi-Wing Fu, Changhe Tu, Baoquan Chen, Zhanglin Cheng",http://www.yunhaiwang.org/bankto45/as-tvcg.pdf,"The aspect ratio of a line chart heavily influences the perception of the underlying data. Different methods explore different criteria in choosing aspect ratios, but so far, it was still unclear how to select aspect ratios appropriately for any given data. This paper provides a guideline for the user to choose aspect ratios for any input 1D curves by conducting an in-depth analysis of aspect ratio selection methods both theoretically and experimentally. By formulating several existing methods as line integrals, we explain their parameterization invariance. Moreover, we derive a new and improved aspect ratio selection method, namely the†L1-LOR (local orientation resolution), with a certain degree of parameterization invariance. Furthermore, we connect different methods, including AL (arc length based method), the banking to 45∞ principle, RV (resultant vector) and AS (average absolute slope), as well as†L1-LOR and AO (average absolute orientation). We verify these connections by a comparative evaluation involving various data sets, and show that the selections by RV and†L1-LOR are complementary to each other for most data. Accordingly, we propose the dual-scale banking technique that combines the strengths of RV and†L1-LOR, and demonstrate its practicability using multiple real-world data sets.",,,,,vimeo 289789006,,,2018,InfoVis,"Convention Hall 1, Section D",Thursday,Perception & Cognition 1,25-Oct,3:20 PM,3:40 PM,
InfoVis,TVCG,Image-based Aspect Ratio Selection ,J),"Yunhai Wang, Zeyu Wang, Chi-Wing Fu, Hansj√∂rg Schmauder, Oliver Deussen, Daniel Weiskopf",http://www.yunhaiwang.org/infovis18/dbar/paper.pdf,"Selecting a good aspect ratio is crucial for effective 2D diagrams. There are several aspect ratio selection methods for function plots and line charts, but only few can handle general, discrete diagrams such as 2D scatter plots. However, these methods either lack a perceptual foundation or heavily rely on intermediate isoline representations, which depend on choosing the right isovalues and are time-consuming to compute. This paper introduces a general image-based approach for selecting aspect ratios for a wide variety of 2D diagrams, ranging from scatter plots and density function plots to line charts. Our approach is derived from Federerís co-area formula and a line integral representation that enable us to directly construct image-based versions of existing selection methods using density fields. In contrast to previous methods, our approach bypasses isoline computation, so it is faster to compute, while following the perceptual foundation to select aspect ratios. Furthermore, this approach is complemented by an anisotropic kernel density estimation to construct density fields, allowing us to more faithfully characterize data patterns, such as the subgroups in scatterplots or dense regions in time series. We demonstrate the effectiveness of our approach by quantitatively comparing to previous methods and revisiting a prior user study. Finally, we present extensions for ROI banking, multi-scale banking, and the application to image data.",,,,,vimeo 289784435,,2018,2018,InfoVis,"Convention Hall 1, Section D",Thursday,Perception & Cognition 1,25-Oct,3:40 PM,4:00 PM,
SciVis,TVCG,Persistence Atlas for Critical Point Variability in Ensembles ,J),"Guillaume Favelier, Noura Faraj, Brian Summa, Julien Tierny",,,,,,,vimeo 290325207,,2018,2018,SciVis,Estrel A+B,Thursday,"Topology, Geometry, and Precision",25-Oct,2:20 PM,2:40 PM,
SciVis,TVCG,Probabilistic Asymptotic Decider for Topological Ambiguity Resolution in Level-Set Extraction for Uncertain 2D Data ,J),"Tushar Athawale, Chris R. Johnson",,,,,,,vimeo 290325318,,2018,2018,SciVis,Estrel A+B,Thursday,"Topology, Geometry, and Precision",25-Oct,2:40 PM,3:00 PM,
SciVis,TVCG,Hexahedral Mesh Structure Visualization and Evaluation ,J),"Kaoji Cotrik Xu, Guoning Chen",,,,,,,vimeo 290327525,,2018,2018,SciVis,Estrel A+B,Thursday,"Topology, Geometry, and Precision",25-Oct,3:00 PM,3:20 PM,
SciVis,TVCG,Shared-Memory Parallel Computation of Morse-Smale Complexes with Improved Accuracy ,J),"Attila Gyulassy, Peer-Timo Bremer, Valerio Pascucci",,,,,,,vimeo 290328033,,2018,2018,SciVis,Estrel A+B,Thursday,"Topology, Geometry, and Precision",25-Oct,3:20 PM,3:40 PM,
SciVis,TVCG,A Study of the Trade-off between Reduced Precision and Resolution for Scientific Data Analysis and Visualization ,J),"Duong Hoang, Pavol Klacansky, Harsh Bhatia, Peer-Timo Bremer, Peter Lindstrom, Valerio Pascucci",,,,,,,vimeo 290328254,,2018,2018,SciVis,Estrel A+B,Thursday,"Topology, Geometry, and Precision",25-Oct,3:40 PM,4:00 PM,
SciVis,SciVis,An Organic Visual Metaphor for Public Understanding of Conditional Co-occurrences,,"Keshav Dasu, Takanori Fujiwara, Kwan-Liu Ma",,,,,,,vimeo 290328908,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Visual Abstractions, Perceptual Study and Immersive Visualization",25-Oct,2:20 PM,2:32 PM,
SciVis,SciVis,VAPLI: Novel Visual Abstraction for Protein-Lipid Interactions,,"Naif Alharbi, Matthieu Chavent, Michael Krone, Robert S. Laramee",,,,,,,vimeo 290328550,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Visual Abstractions, Perceptual Study and Immersive Visualization",25-Oct,2:32 PM,2:44 PM,
SciVis,SciVis,Color Interpolation for non-Euclidean Color Spaces,,"Max Zeyen, Tobias Post, Hans Hagen, James Ahrens, David Rogers, Roxana Bujack",,,,,,,vimeo 290328621,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Visual Abstractions, Perceptual Study and Immersive Visualization",25-Oct,2:45 PM,2:57 PM,
SciVis,SciVis,VRGE: An Immersive Visualization Application for the Geosciences,,"David A. B. Hyde, Tyler R. Hall, Jef Caers",,,,,,,vimeo 290328472,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Visual Abstractions, Perceptual Study and Immersive Visualization",25-Oct,2:57 PM,3:09 PM,
SciVis,SciVis,3De Interactive Lenses for Visualization in Virtual Environments,,"Roberta C. R. Mota, Allan Rocha, Julio D. Silva, Usman R. Alim, Ehud Sharlin",,,,,,,vimeo 290328419,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Visual Abstractions, Perceptual Study and Immersive Visualization",25-Oct,3:10 PM,3:22 PM,
SciVis,SciVis,Toward A Deep Understanding of What Makes a Scientific Visualization Memorable,,"Rui Li, Jian Chen",,,,,,,vimeo 290328799,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Visual Abstractions, Perceptual Study and Immersive Visualization",25-Oct,3:22 PM,3:34 PM,
SciVis,SciVis,Ordering Perceptions about Perceptual Order,,"Roxana Bujack, Terece L Turton, David Rogers, James Ahrens",,,,,,,vimeo 290328692,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Visual Abstractions, Perceptual Study and Immersive Visualization",25-Oct,3:35 PM,3:47 PM,
SciVis,SciVis,QuFlow: Visualizing Parameter Flow in Quantum Circuits for Understanding Quantum Computation,,"Siyuan Lin, Hao Jiang, Lingyun Sun",,,,,,,vimeo 290328716,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Visual Abstractions, Perceptual Study and Immersive Visualization",25-Oct,3:47 PM,3:59 PM,
VAST,TVCG,RuleMatrix: Visualizing and Understanding Classifiers with Rules ,J),"Yao Ming, Huamin Qu, Enrico Bertini",,,,,,,vimeo 289787299,,2018,2018,VAST,"Convention Hall 1, Section C",Thursday,Explainable ML,25-Oct,4:20 PM,4:40 PM,
VAST,TVCG,Seq2Seq-Vis: A Visual Debugging Tool for Sequence to Sequence Models ,J),"Hendrik Strobelt, Sebastian Gehrmann, Michael Behrisch, Adam Perer, Hanspeter Pfister, Alexander M. Rush",,,,,,,vimeo 289787650,,2018,2018,VAST,"Convention Hall 1, Section C",Thursday,Explainable ML,25-Oct,4:40 PM,5:00 PM,
VAST,TVCG,Manifold: A Model-Agnostic Framework for Interpretation and Diagnosis of Machine Learning Models ,J),"Jiawei Zhang, Yang Wang, Piero Molino, Lezhi Li, David Ebert",,,,,,,vimeo 289787203,,2018,2018,VAST,"Convention Hall 1, Section C",Thursday,Explainable ML,25-Oct,5:00 PM,5:20 PM,
VAST,TVCG,Visual Analytics for Topic Model Optimization based on User-Steerable Speculative Execution ,J),"Mennatallah El-Assady, Fabian Sperrle, Oliver Deussen, Daniel Keim, Christopher Collins",,,,,,,vimeo 289787264,,2018,2018,VAST,"Convention Hall 1, Section C",Thursday,Explainable ML,25-Oct,5:20 PM,5:40 PM,
VAST,TVCG,VIS4ML: An Ontology for Visual Analytics Assisted Machine Learning ,J),"Dominik Sacha, Matthias Kraus, Daniel Keim, Min Chen",,,,,,,vimeo 289787814,,2018,2018,VAST,"Convention Hall 1, Section C",Thursday,Explainable ML,25-Oct,5:40 PM,6:00 PM,
InfoVis,TVCG,Mitigating the Attraction Effect with Visualizations ,J),"Evanthia Dimara, Gilles Bailly, Anastasia Bezerianos, Steven Franconeri",https://hal.inria.fr/hal-01845004v2/document,"Human decisions are prone to biases, and this is no less true for decisions made within data visualizations. Bias mitigation strategies often focus on the person, by educating people about their biases, typically with little success. We focus instead on the system, presenting the first evidence that altering the design of an interactive visualization tool can mitigate a strong bias ñ the attraction effect. Participants viewed 2D scatterplots where choices between superior alternatives were affected by the placement of other suboptimal points. We found that highlighting the superior alternatives weakened the bias, but did not eliminate it. We then tested an interactive approach where participants completely removed locally dominated points from the view, inspired by the elimination by aspects strategy in the decision-making literature. This approach strongly decreased the bias, leading to a counterintuitive suggestion: tools that allow removing inappropriately salient or distracting data from a view may help lead users to make more rational decisions.",,https://aviz.fr/deletion,https://aviz.fr/deletion,,vimeo 289784657,,2018,2018,InfoVis,"Convention Hall 1, Section D",Thursday,Perception & Cognition 2,25-Oct,4:20 PM,4:40 PM,
InfoVis,TVCG,Face to Face: Evaluating Visual Comparison ,J),"Brian David Ondov, Nicole Jardine, Niklas Elmqvist, Steven Franconeri",http://users.umiacs.umd.edu/~elm/projects/face2face/face2face.pdf,"Data are often viewed as a single set of values, but those values frequently must be compared with another set. The existing evaluations of designs that facilitate these comparisons tend to be based on intuitive reasoning, rather than quantifiable measures. We build on this work with a series of crowdsourced experiments that use low-level perceptual comparison tasks that arise frequently in comparisons within data visualizations (e.g., which value changes the most between the two sets of data?). Participants completed these tasks across a variety of layouts: overlaid, two arrangements of juxtaposed small multiples, mirror-symmetric small multiples, and animated transitions. A staircase procedure sought the difficulty level (e.g., value change delta) that led to equivalent accuracy for each layout. Confirming prior intuition, we observe high levels of performance for overlaid versus standard small multiples. However, we also find performance improvements for both mirror symmetric small multiples and animated transitions. While some results are incongruent with common wisdom in data visualization, they align with previous work in perceptual psychology, and thus have potentially strong implications for visual comparison designs.",,,,,vimeo 289785372,,2018,2018,InfoVis,"Convention Hall 1, Section D",Thursday,Perception & Cognition 2,25-Oct,4:40 PM,5:00 PM,
TVCG,TVCG,Task-Based Effectiveness of Basic Visualizations ,T),"Bahador Saket, Alex Endert, √áagatay Demiralp",https://arxiv.org/pdf/1709.08546.pdf,"Visualizations of tabular data are widely used; understanding their effectiveness in different task and data contexts is fundamental to scaling their impact. However, little is known about how basic tabular data visualizations perform across varying data analysis tasks. In this paper, we report results from a crowdsourced experiment to evaluate the effectiveness of five small scale (5-34 data points) two-dimensional visualization typesóTable, Line Chart, Bar Chart, Scatterplot, and Pie Chartóacross ten common data analysis tasks using two datasets. We find the effectiveness of these visualization types significantly varies across task, suggesting that visualization design would benefit from considering context-dependent effectiveness. Based on our findings, we derive recommendations on which visualizations to choose based on different tasks. We finally train a decision tree on the data we collected to drive a recommender, showcasing how to effectively engineer experimental user data into practical visualization systems.",,,https://github.com/gtvalab/ChartsEffectiveness/tree/master/Raw-Data,,vimeo 289789506,,,2018,InfoVis,"Convention Hall 1, Section D",Thursday,Perception & Cognition 2,25-Oct,5:00 PM,5:20 PM,
InfoVis,TVCG,At a Glance: Approximate Entropy as a Measure of Line Chart Visualization Complexity ,J),"Eugene Wu, Remco Chang, Abigail Mosca, Gabriel Ryan",,,,,,,vimeo 289784475,,2018,2018,InfoVis,"Convention Hall 1, Section D",Thursday,Perception & Cognition 2,25-Oct,5:20 PM,5:40 PM,
TVCG,TVCG,Correlation Judgment and Visualization Features: A Comparative Study ,T),"Fumeng Yang, Lane Harrison, Ronald A. Rensink, Steven Franconeri, Remco Chang",https://github.com/Fumeng-Yang/VisualFeature_TVCG/blob/master/paper/VF_preprint.pdf,"Recent visualization research efforts have incorporated experimental techniques and perceptual models from the vision science community. Perceptual laws such as Weberís law, for example, have been used to model the perception of correlation in scatterplots. While this thread of research has progressively refined the modeling of the perception of correlation in scatterplots, it remains unclear as to why such perception can be modeled using relatively simple functions, e.g., linear and log-linear. In this paper, we investigate a longstanding hypothesis that people use visual features in a chart as a proxy for statistical measures like correlation. For a given scatterplot, we extract 49 candidate visual features and evaluate which best align with existing models and participant judgments. The results support the hypothesis that people attend to a small number of visual features when discriminating correlation in scatterplots. We discuss how this result may account for prior conflicting findings, and how visual features provide a baseline for future model-based approaches in visualization evaluation and design.",,,,,vimeo 289789613,,,2018,InfoVis,"Convention Hall 1, Section D",Thursday,Perception & Cognition 2,25-Oct,5:40 PM,6:00 PM,
SciVis,TVCG,Firefly: Illumination Drones for Interactive Visualization ,J),"Sergej Stoppel, Magnus Paulson Erga, Stefan Bruckner",,,,,,,vimeo 290325505,,2018,2018,SciVis,Estrel Hall A+B,Thursday,Interaction and Multivariate Data,25-Oct,4:20 PM,4:40 PM,
SciVis,TVCG,CoDDA: A Flexible Copula-based Distribution Driven Analysis Framework for Large-Scale Multivariate Data ,J),"Subhashis Hazarika, Soumya Dutta, Han-Wei Shen, Jen-Ping Chen",,,,,,,vimeo 290325658,,2018,2018,SciVis,Estrel Hall A+B,Thursday,Interaction and Multivariate Data,25-Oct,4:40 PM,5:00 PM,
SciVis,TVCG,"Details-First, Show Context, Overview Last: Supporting Exploration of Viscous Fingers in Large-Scale Ensemble Simulations ",J),"Timothy Basil Luciani, Andrew T Burks, Cassiano Sugiyama, Jonathan Komperda, Liz G.Elisabeta Marai",,,,,,,vimeo 290328058,,2018,2018,SciVis,Estrel Hall A+B,Thursday,Interaction and Multivariate Data,25-Oct,5:00 PM,5:20 PM,
TVCG,TVCG,A Model of Spatial Directness in Interactive Visualization ,T),"Stefan Bruckner, Tobias Isenberg, Timo Ropinski, Alexander Wiebel",,,,,,,vimeo 289789140,,,2018,SciVis,Estrel Hall A+B,Thursday,Interaction and Multivariate Data,25-Oct,5:20 PM,5:40 PM,
TVCG,TVCG,Decal-Lenses: Interactive Lenses on Surfaces for Multivariate Visualization ,T),"Allan Rocha, Julio Daniel Silva, Usman R. Alim, Sheelagh Carpendale, Mario Costa Sousa",,,,,,,vimeo 289789528,,,2018,SciVis,Estrel Hall A+B,Thursday,Interaction and Multivariate Data,25-Oct,5:40 PM,6:00 PM,
SciVis,SciVis,Cluster-Based Visualization for Merger Tree Data: The Challenge of Missing Expectations,,"Annie Preston, Kwan-Liu Ma",,,,,,,vimeo 290328886,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Flow, Astrophysics, and Computationally Intensive Data Visualization",25-Oct,4:20 PM,4:32 PM,
SciVis,SciVis,Visualization of Uncertainty for Computationally Intensive Simulations Using High Fidelity Emulators,,"Ayan Biswas, Earl Lawrence, James Ahrens",,,,,,,vimeo 290328642,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Flow, Astrophysics, and Computationally Intensive Data Visualization",25-Oct,4:32 PM,4:44 PM,
SciVis,SciVis,A Lagrangian Method for Extracting Eddy Boundaries in the Red Sea and the Gulf of Aden,,"Anke Friederici, Habib Toye, Ibrahim Hoteit, Tino Weinkauf, Holger Theisel, Markus Hadwiger",,,,,,,vimeo 290328836,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Flow, Astrophysics, and Computationally Intensive Data Visualization",25-Oct,4:45 PM,4:57 PM,
SciVis,SciVis,FTLE Ridge Lines for Long Integration Times,,"Thomas Wilde, Christian R√∂ssl, Holger Theisel",,,,,,,vimeo 290328753,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Flow, Astrophysics, and Computationally Intensive Data Visualization",25-Oct,4:57 PM,5:09 PM,
SciVis,SciVis,Ocean Current Segmentation at Different Depths and Correlation with Temperature in a MPAS-Ocean Simulation,,"Petra Gospodnetic, Divya Banesh, Philip Wolfram, Mark Petersen, Hans Hagen, James Ahrens, Markus Rauhut",,,,,,,vimeo 290328665,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Flow, Astrophysics, and Computationally Intensive Data Visualization",25-Oct,5:10 PM,5:22 PM,
SciVis,SciVis,"TimeTubes: Automatic Extraction of Observable Blazar Features from Long-Term, Multi-Dimensional Datasets",,"Naoko Sawada, Masanori Nakayama, Makoto Uemura, Issei Fujishiro",,,,,,,vimeo 290328934,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Flow, Astrophysics, and Computationally Intensive Data Visualization",25-Oct,5:22 PM,5:34 PM,
SciVis,SciVis,aflak: Pluggable Visual Programming Environment with Quick Feedback Loop Tuned for Astrophysical Observations,,"Malik Olivier Boussejra, Kazuya Matsubayashi, Yuriko Takeshima, Shunya Takekawa, Rikuo Uchiki, Makoto Uemura, Issei Fujishiro",,,,,,,vimeo 290328343,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Flow, Astrophysics, and Computationally Intensive Data Visualization",25-Oct,5:35 PM,5:47 PM,
SciVis,SciVis,Biclusters based Visual Exploration of Multivariate Scientific Data,,"Xiangyang He, Yubo Tao, Qirui Wang, Hai Lin",,,,,,,vimeo 290328582,,2018,2018,SciVis Short Papers,Estrel Hall C,Thursday,"Flow, Astrophysics, and Computationally Intensive Data Visualization",25-Oct,5:47 PM,6:00 PM,
VAST,TVCG,MAQUI: Interweaving Queries and Pattern Mining for Recursive Event Sequence Exploration ,J),"Po-Ming Law, Zhicheng Liu, Sana Malik, Rahul Basole",,,,,,,vimeo 289787863,,2018,2018,VAST,"Convention Hall 1, Section C",Friday,"Event, Sequence, and ML",26-Oct,9:00 AM,9:20 AM,
VAST,TVCG,iForest: Interpreting Random Forests via Visual Analytics ,J),"Xun Zhao, Yanhong Wu, Dik Lun Lee, Weiwei Cui",,,,,,,vimeo 289787165,,2018,2018,VAST,"Convention Hall 1, Section C",Friday,"Event, Sequence, and ML",26-Oct,9:20 AM,9:40 AM,
VAST,TVCG,Visual Progression Analysis of Event Sequence Data ,J),"Shunan Guo, Zhuochen Jin, David Gotz, Fan Du, Hongyuan Zha, Nan Cao",,,,,,,vimeo 289787414,,2018,2018,VAST,"Convention Hall 1, Section C",Friday,"Event, Sequence, and ML",26-Oct,9:40 AM,10:00 AM,
TVCG,TVCG,StreamExplorer: A Multi-Stage System for Visually Exploring Events in Social Streams ,T),"Yingcai Wu, Zhutian Chen, Guodao Sun, Xiao Xie, Nan Cao, Shixia Liu, Weiwei Cui",,,,,,,vimeo 289788908,,,2018,VAST,"Convention Hall 1, Section C",Friday,"Event, Sequence, and ML",26-Oct,10:00 AM,10:20 AM,
VAST,TVCG,Duet: Helping Data Analysis Novices Conduct Pairwise Comparisons by Minimal Specification ,J),"Po-Ming Law, Rahul Basole, Yanhong Wu",,,,,,,vimeo 289787850,,2018,2018,VAST,"Convention Hall 1, Section C",Friday,"Event, Sequence, and ML",26-Oct,10:20 AM,10:40 AM,
InfoVis,TVCG,Visualizing Uncertain Tropical Cyclone Predictions using Representative Samples from Ensembles of Forecast Tracks ,J),"Le Liu, Lace M. K. Padilla, Sarah Creem-Regehr, Donald House",http://lacepadilla.com/Downloads/publications/Liuetal_2018.pdf,"A common approach to sampling the space of a prediction is the generation of an ensemble of potential outcomes, where the ensembleís distribution reveals the statistical structure of the prediction space. For example, the US National Hurricane Center generates multiple day predictions for a stormís path, size, and wind speed, and then uses a Monte Carlo approach to sample this prediction into a large ensemble of potential storm outcomes. Various forms of summary visualizations are generated from such an ensemble, often using spatial spread to indicate its statistical characteristics. However, studies have shown that changes in the size of such summary glyphs, representing changes in the uncertainty of the prediction, are frequently confounded with other attributes of the phenomenon, such as its size or strength. In addition, simulation ensembles typically encode multivariate information, which can be difficult or confusing to include in a summary display. This problem can be overcome by directly displaying the ensemble as a set of annotated trajectories, however this solution will not be effective if ensembles are densely overdrawn or structurally disorganized. We propose to overcome these difficulties by selectively sampling the original ensemble, constructing a smaller representative and spatially well organized ensemble. This can be drawn directly as a set of paths that implicitly reveals the underlying spatial uncertainty distribution of the prediction. Since this approach does not use a visual channel to encode uncertainty, additional information can more easily be encoded in the display without leading to visual confusion. To demonstrate our argument, we describe the development of a visualization for ensembles of tropical cyclone forecast tracks, explaining how their spatial and temporal predictions, as well as other crucial storm characteristics such as size and intensity, can be clearly revealed. We verify the effectiveness of this visualization approach through a cognitive study exploring how storm damage estimates are affected by the density of tracks drawn, and by the presence or absence of annotating information on storm size and intensity.",,https://osf.io/hy3ba/,https://osf.io/hy3ba/,,vimeo 289784601,,2018,2018,InfoVis,"Convention Hall 1, Section D",Friday,Uncertainty & Error,26-Oct,9:00 AM,9:20 AM,
InfoVis,TVCG,Hypothetical Outcome Plots Help Untrained Observers Judge Trends in Ambiguous Data ,J),"Alex Kale, Francis Nguyen, Matthew Kay, Jessica Hullman",http://users.eecs.northwestern.edu/~jhullman/hops_jobs_pfs.pdf,"Animated representations of outcomes drawn from distributions (hypothetical outcome plots, or HOPs) are used in the media and other public venues to communicate uncertainty. HOPs greatly improve multivariate probability estimation over conventional static uncertainty visualizations and leverage the ability of the visual system to quickly, accurately, and automatically process the summary statistical properties of ensembles. However, it is unclear how well HOPs support applied tasks resembling real world judgments posed in uncertainty communication. We identify and motivate an appropriate task to investigate realistic judgments of uncertainty in the public domain through a qualitative analysis of uncertainty visualizations in the news. We contribute two crowdsourced experiments comparing the effectiveness of HOPs, error bars, and line ensembles for supporting perceptual decision-making from visualized uncertainty. Participants infer which of two possible underlying trends is more likely to have produced a sample of time series data by referencing uncertainty visualizations which depict the two trends with variability due to sampling error. By modeling each participantís accuracy as a function of the level of evidence presented over many repeated judgments, we find that observers are able to correctly infer the underlying trend in samples conveying a lower level of evidence when using HOPs rather than static aggregate uncertainty visualizations as a decision aid. Modeling approaches like ours contribute theoretically grounded and richly descriptive accounts of user perceptions to visualization evaluation.",,,https://github.com/kalealex/jobs-report-hops,https://osf.io/8cte3/registrations/,vimeo 289785258,,2018,2018,InfoVis,"Convention Hall 1, Section D",Friday,Uncertainty & Error,26-Oct,9:20 AM,9:40 AM,
InfoVis,TVCG,In Pursuit of Error: A Survey of Uncertainty Visualization Evaluation ,J),"Jessica Hullman, Xiaoli Qiao, Michael Correll, Alex Kale, Matthew Kay",https://research.tableau.com/sites/default/files/uncertainty_vis_eval.pdf,"Understanding and accounting for uncertainty is critical to effectively reasoning about visualized data. However, evaluating the impact of an uncertainty visualization is complex due to the difficulties that people have interpreting uncertainty and the challenge of defining correct behavior with uncertainty information. Currently, evaluators of uncertainty visualization must rely on general purpose visualization evaluation frameworks which can be ill-equipped to provide guidance with the unique difficulties of assessing judgments under uncertainty. To help evaluators navigate these complexities, we present a taxonomy for characterizing decisions made in designing an evaluation of an uncertainty visualization. Our taxonomy differentiates six levels of decisions that comprise an uncertainty visualization evaluation: the behavioral targets of the study, expected effects from an uncertainty visualization, evaluation goals, measures, elicitation techniques, and analysis approaches. Applying our taxonomy to 86 user studies of uncertainty visualizations, we find that existing evaluation practice, particularly in visualization research, focuses on Performance and Satisfaction-based measures that assume more predictable and statistically-driven judgment behavior than is suggested by research on human judgment and decision making. We reflect on common themes in evaluation practice concerning the interpretation and semantics of uncertainty, the use of confidence reporting, and a bias toward evaluating performance as accuracy rather than decision quality. We conclude with a concrete set of recommendations for evaluators designed to reduce the mismatch between the conceptualization of uncertainty in visualization versus other fields.",,,,,vimeo 289785271,,2018,2018,InfoVis,"Convention Hall 1, Section D",Friday,Uncertainty & Error,26-Oct,9:40 AM,10:00 AM,
InfoVis,TVCG,Where's my data? Evaluating Visualizations with Missing Data ,J),"Hayeong Song, Danielle Albers Szafir",http://cmci.colorado.edu/visualab/papers/song_VIS_2018.pdf,Many real-world datasets are incomplete due to factors such as data collection failures or misalignments between fused datasets. Visualizations of incomplete datasets should allow analysts to draw conclusions from their data while effectively reasoning about the quality of the data and resulting conclusions. We conducted a pair of crowdsourced studies to measure how the methods used to impute and visualize missing data may influence analysts' perceptions of data quality and their confidence in their conclusions. Our experiments used different design choices for line graphs and bar charts to estimate averages and trends in incomplete time series datasets. Our results provide preliminary guidance for visualization designers to consider when working with incomplete data in different domains and scenarios.,,,http://cmci.colorado.edu/visualab/MissingData/,,vimeo 289785184,,2018,2018,InfoVis,"Convention Hall 1, Section D",Friday,Uncertainty & Error,26-Oct,10:00 AM,10:20 AM,
InfoVis,TVCG,A Framework for Externalizing Implicit Error Using Visualization,,"Nina McCurdy, Julie Gerdes, Miriah Meyer",http://sci.utah.edu/~vdl/papers/2018_infovis_IE-Framework.pdf,"This paper presents a framework for externalizing and analyzing expert knowledge about discrepancies in data through the use of visualization. Grounded in an 18-month design study with global health experts, the framework formalizes the notion of data discrepancies as implicit error, both in global health data and more broadly. We use the term implicit error to describe measurement error that is inherent to and pervasive throughout a dataset, but that isnít explicitly accounted for or defined. Instead, implicit error exists in the minds of experts, is mainly qualitative, and is accounted for subjectively during expert interpretation of the data. Externalizing knowledge surrounding implicit error can assist in synchronizing, validating, and enhancing interpretation, and can inform error analysis and mitigation. The framework consists of a description of implicit error components that are important for downstream analysis, along with a process model for externalizing and analyzing implicit error using visualization. As a second contribution, we provide a rich, reflective, and verifiable description of our research process as an exemplar summary toward the ongoing inquiry into ways of increasing the validity and transferability of design study research.",,,,,vimeo 289785202,,2018,2018,InfoVis,"Convention Hall 1, Section D",Friday,Uncertainty & Error,26-Oct,10:20 AM,10:40 AM,
SciVis,TVCG,Exploring Time-Varying Multivariate Volume Data Using Matrix of Isosurface Similarity Maps ,J),"Jun Tao, Martin Imre, Chaoli Wang, Nitesh V Chawla, Hanqi Guo, G√∂khan Sever, Seung Hyun Kim",,,,,,,vimeo 290325769,,2018,2018,SciVis,Estrel Hall C,Friday,Time-varying Data,26-Oct,9:00 AM,9:20 AM,
SciVis,TVCG,Visual Analysis of Spatio-temporal Relations of Pairwise Attributes in Unsteady Flow ,J),"Marzieh Berenjkoub, Rodolfo Ostilla Monico, Robert S. Laramee, Guoning Chen",,,,,,,vimeo 290325964,,2018,2018,SciVis,Estrel Hall C,Friday,Time-varying Data,26-Oct,9:20 AM,9:40 AM,
SciVis,TVCG,Time-Dependent Flow seen through Approximate Observer Killing Fields ,J),"Markus Hadwiger, Matej Mlejnek, Thomas Theussl, Peter Rautek",,,,,,,vimeo 290327432,,2018,2018,SciVis,Estrel Hall C,Friday,Time-varying Data,26-Oct,9:40 AM,10:00 AM,
TVCG,TVCG,An Exploratory Framework for Cyclone Identification and Tracking ,T),"Akash Anil Valsangkar, Joy Merwin Monteiro, Vidya Narayanan, Ingrid Hotz, Vijay Natarajan",,,,,,,vimeo 289789170,,,2018,SciVis,Estrel Hall C,Friday,Time-varying Data,26-Oct,10:00 AM,10:20 AM,
TVCG,TVCG,Popup-Plots: Warping Temporal Data Visualization ,T),"Johanna Schmidt, Dominik Fleischmann, Bernhard Preim, Norbert Brandle, Gabriel Mistelbauer",,,,,,,vimeo 289789393,,,2018,SciVis,Estrel Hall C,Friday,Time-varying Data,26-Oct,10:20 AM,10:40 AM,
